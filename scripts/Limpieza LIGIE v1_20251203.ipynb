{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6d759b",
   "metadata": {},
   "source": [
    "# Limpieza LIGIE\n",
    "## Fases de Tratado\n",
    "### Fase 0: Configuración General\n",
    "\n",
    "Antes de iniciar cualquier lógica, es fundamental preparar el entorno de ejecución instalando las dependencias necesarias y comprendiendo las herramientas que manipularán el archivo PDF y las estructuras de datos.\n",
    "\n",
    "Instalación de dependencias: Para asegurar que el script funcione correctamente, se deben instalar las librerías externas que no vienen incluidas por defecto en Python. Ejecuta el siguiente comando en tu terminal o en una celda de tu entorno de desarrollo:\n",
    "\n",
    "- pip install pdfplumber pandas numpy xlsxwriter\n",
    "\n",
    "Librerías:\n",
    "\n",
    "- pdfplumber: Es el motor principal de extracción. Se elige sobre otras opciones (como PyPDF2) porque permite estrategias visuales (detección de líneas de tablas) y lectura de texto posicional precisa.\n",
    "\n",
    "- pandas (pd): Utilizada para crear los DataFrames. Es vital para manipular filas, columnas, rellenar datos faltantes (NaN) y transformar texto masivamente.\n",
    "\n",
    "- numpy (np): Se usa auxiliarmente para definir valores nulos (np.nan) que pandas pueda reconocer y tratar.\n",
    "\n",
    "- re: Librería de Expresiones Regulares. Es el \"cerebro\" que identifica patrones de texto complejos (ej. detectar si una línea empieza con \"Sección IV\" o \"Capítulo 85\").\n",
    "\n",
    "- os: Utilidad de sistema operativo para manejo de rutas de archivos.\n",
    "\n",
    "Variables Globales:\n",
    "\n",
    "- os.chdir(''): Define el directorio de trabajo.\n",
    "\n",
    "- PDF_PATH: Define la ruta del archivo origen.\n",
    "\n",
    "- CODIGO_STOP: El script dejará de leer el PDF cuando encuentre este código específico (9807.00.01), optimizando tiempo al evitar leer anexos irrelevantes al final del documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0947e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pdfplumber pandas numpy xlsxwriter\n",
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "#os.chdir('C:/Users/M20537/Downloads')\n",
    "PDF_PATH = \"LIGIE-UNIFICADA-LIGIE_20250728-20250728.pdf\"\n",
    "CODIGO_STOP = \"9807.00.01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f81d8",
   "metadata": {},
   "source": [
    "### Fase 1: Generación de Catálogos\n",
    "\n",
    "Esta es la fase más compleja de lógica de texto. Su objetivo es leer el índice inicial del PDF para entender qué significa \"Capítulo 01\" o \"Sección V\", resolviendo el problema de que los títulos se cortan entre páginas.\n",
    "\n",
    "Lectura Masiva:\n",
    "\n",
    "- En lugar de procesar página por página, el script lee las primeras N páginas (configurado a 25) y extrae todo el texto.\n",
    "\n",
    "- Acción: Convierte todas las páginas en una lista única y continua de líneas de texto (all_lines).\n",
    "\n",
    "- Propósito: Eliminar la noción de \"salto de página\". Para el código, la línea final de la página 3 y la primera de la página 4 son contiguas.\n",
    "\n",
    "Filtrado de \"Basura\":\n",
    "\n",
    "- Se define una lista negra (TEXTOS_BASURA) con encabezados recurrentes (\"Secretaría de Economía\", \"Dirección General...\", \"Página\", etc.).\n",
    "\n",
    "- El script descarta cualquier línea que contenga estas frases, sea solo numérica (números de página) o sea demasiado corta. Esto limpia el \"ruido\" visual del PDF.\n",
    "\n",
    "Búsqueda \"Lookahead\":\n",
    "\n",
    "- El script recorre la lista de líneas buscando patrones Regex de Sección [Romano] o Capítulo [Arábigo].\n",
    "\n",
    "- Al encontrar uno (ej. \"Capítulo 41\"), busca su descripción.\n",
    "\n",
    "- Lógica Crítica: Si la descripción no está en la misma línea, el script entra en un bucle que revisa las siguientes 15 líneas. Salta cualquier texto basura hasta encontrar una línea con texto válido (ej. \"Pieles y cueros\").\n",
    "\n",
    "- Si encuentra otro Capítulo o Sección antes de encontrar una descripción, se detiene para evitar errores cruzados.\n",
    "\n",
    "Limpieza de Texto (limpiar_descripcion):\n",
    "\n",
    "- Una vez hallada la descripción, se eliminan los puntos suspensivos del índice (....) y los números de página finales (390), dejando solo el texto puro (\"Pieles y cueros\").\n",
    "\n",
    "Mapeo Jerárquico:\n",
    "\n",
    "- Se guardan los resultados en diccionarios (dict_capitulos, dict_secciones).\n",
    "\n",
    "- Se crea un mapa de relación (mapa_cap_sec) que recuerda qué Sección estaba activa cuando se leyó un Capítulo. Esto permite saber después que el Capítulo 01 pertenece a la Sección I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1acae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FASE 1: Generando catálogos (Escanear primeras 25 págs) ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dict_capitulos, dict_secciones, mapa_cap_sec\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Ejecutar Fase 1\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m CAPITULOS_NOMBRES, SECCIONES_NOMBRES, MAPA_CAPITULO_SECCION = \u001b[43mgenerar_catalogos_final\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDF_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCatálogos listos: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(CAPITULOS_NOMBRES)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Capítulos detectados.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mgenerar_catalogos_final\u001b[39m\u001b[34m(pdf_path, paginas_a_escanear)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(limit):\n\u001b[32m     29\u001b[39m     page = pdf.pages[i]\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     text = \u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m text:\n\u001b[32m     32\u001b[39m         lines = [l.strip() \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m text.split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m l.strip()]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfplumber\\page.py:530\u001b[39m, in \u001b[36mPage.extract_text\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_textmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtuplify_list_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.as_string\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfplumber\\page.py:507\u001b[39m, in \u001b[36mPage._get_textmap\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    505\u001b[39m     defaults.update({\u001b[33m\"\u001b[39m\u001b[33mlayout_height\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.height})\n\u001b[32m    506\u001b[39m full_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = {**defaults, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m utils.chars_to_textmap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchars\u001b[49m, **full_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfplumber\\container.py:52\u001b[39m, in \u001b[36mContainer.chars\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchars\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> T_obj_list:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjects\u001b[49m.get(\u001b[33m\"\u001b[39m\u001b[33mchar\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfplumber\\page.py:346\u001b[39m, in \u001b[36mPage.objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_objects\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28mself\u001b[39m._objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfplumber\\page.py:443\u001b[39m, in \u001b[36mPage.parse_objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list]:\n\u001b[32m    442\u001b[39m     objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = {}\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_layout_objects(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayout\u001b[49m._objs):\n\u001b[32m    444\u001b[39m         kind = obj[\u001b[33m\"\u001b[39m\u001b[33mobject_type\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33manno\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfplumber\\page.py:266\u001b[39m, in \u001b[36mPage.layout\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    264\u001b[39m interpreter = PDFPageInterpreter(\u001b[38;5;28mself\u001b[39m.pdf.rsrcmgr, device)\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[43minterpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpage_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PdfminerException(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1210\u001b[39m, in \u001b[36mPDFPageInterpreter.process_page\u001b[39m\u001b[34m(self, page)\u001b[39m\n\u001b[32m   1208\u001b[39m     ctm = (\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, -x0, -y0)\n\u001b[32m   1209\u001b[39m \u001b[38;5;28mself\u001b[39m.device.begin_page(page, ctm)\n\u001b[32m-> \u001b[39m\u001b[32m1210\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[38;5;28mself\u001b[39m.device.end_page(page)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1231\u001b[39m, in \u001b[36mPDFPageInterpreter.render_contents\u001b[39m\u001b[34m(self, resources, streams, ctm)\u001b[39m\n\u001b[32m   1229\u001b[39m \u001b[38;5;28mself\u001b[39m.init_resources(resources)\n\u001b[32m   1230\u001b[39m \u001b[38;5;28mself\u001b[39m.init_state(ctm)\n\u001b[32m-> \u001b[39m\u001b[32m1231\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1241\u001b[39m, in \u001b[36mPDFPageInterpreter.execute\u001b[39m\u001b[34m(self, streams)\u001b[39m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1241\u001b[39m         (_, obj) = \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnextobject\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m PSEOF:\n\u001b[32m   1243\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfminer\\psparser.py:659\u001b[39m, in \u001b[36mPSStackParser.nextobject\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    657\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m obj = \u001b[38;5;28mself\u001b[39m.results.pop(\u001b[32m0\u001b[39m)\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:321\u001b[39m, in \u001b[36mPDFContentParser.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflush\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_results(*\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpopall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Edward\\miniconda3\\Lib\\site-packages\\pdfminer\\psparser.py:559\u001b[39m, in \u001b[36mPSStackParser.popall\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    556\u001b[39m     \u001b[38;5;28mself\u001b[39m.curstack[-n:] = []\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m objs\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpopall\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[PSStackEntry[ExtraT]]:\n\u001b[32m    560\u001b[39m     objs = \u001b[38;5;28mself\u001b[39m.curstack\n\u001b[32m    561\u001b[39m     \u001b[38;5;28mself\u001b[39m.curstack = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def generar_catalogos_final(pdf_path, paginas_a_escanear=25):\n",
    "    print(f\"--- FASE 1: Generando catálogos (Escanear primeras {paginas_a_escanear} págs) ---\")\n",
    "    \n",
    "    dict_capitulos = {}\n",
    "    dict_secciones = {}\n",
    "    mapa_cap_sec = {} \n",
    "    \n",
    "    # Regex para capturar el número romano o arábigo\n",
    "    regex_seccion = re.compile(r\"^(?:Sección|SECCIÓN|Seccion)\\s+([IVXLCDM]+)\", re.IGNORECASE) \n",
    "    regex_capitulo = re.compile(r\"^(?:Capítulo|CAPÍTULO|Capitulo)\\s+(\\d+)\", re.IGNORECASE)\n",
    "    \n",
    "    # Textos \"basura\" que interrumpen la lectura\n",
    "    TEXTOS_BASURA = [\n",
    "        \"Calle Pachuca\", \"www.gob.mx\", \"Tel:\", \"(55) 5729\", \n",
    "        \"Economía\", \"Secretaría de Economía\", \n",
    "        \"Dirección General\", \"Facilitación\", \"Comercial y de Comercio Exterior\",\n",
    "        \"PISTON MOLLICA\", \"Versión unificada\", \"Dudas y/o comentarios\",\n",
    "        \"nueva.ligie\", \"Hoja\", \"Página\", \"The following table\", \n",
    "        \"Índice de abreviaturas\", \"Documento referencial\", \n",
    "        \"Ley de los Impuestos\", \"7ma Enmienda\", \"Acuerdo por el que\"\n",
    "    ]\n",
    "\n",
    "    # 1. Carga masiva de líneas\n",
    "    all_lines = []\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            limit = min(paginas_a_escanear, len(pdf.pages))\n",
    "            for i in range(limit):\n",
    "                page = pdf.pages[i]\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    lines = [l.strip() for l in text.split('\\n') if l.strip()]\n",
    "                    all_lines.extend(lines)\n",
    "    except Exception as e:\n",
    "        print(f\"Error crítico leyendo PDF para catálogos: {e}\")\n",
    "        return {}, {}, {}\n",
    "\n",
    "    total_lines = len(all_lines)\n",
    "\n",
    "    # 2. Funciones de limpieza\n",
    "    def es_linea_util(txt):\n",
    "        if not txt: return False\n",
    "        txt_lower = txt.lower()\n",
    "        if any(basura.lower() in txt_lower for basura in TEXTOS_BASURA): return False\n",
    "        if re.match(r'^[\\d\\.\\s]+$', txt): return False\n",
    "        if len(txt) < 3: return False\n",
    "        return True\n",
    "\n",
    "    def limpiar_descripcion(txt):\n",
    "        txt = re.split(r'\\.{2,}', txt)[0]\n",
    "        txt = re.sub(r'\\s+\\d+$', '', txt)\n",
    "        txt = txt.lstrip('.- ').strip()\n",
    "        return txt\n",
    "\n",
    "    def buscar_descripcion_real(start_index, match_obj):\n",
    "        # A. Intentar en la misma línea\n",
    "        parte_match = match_obj.group(0)\n",
    "        resto_linea = all_lines[start_index][len(parte_match):].strip()\n",
    "        resto_linea = re.split(r'\\.{2,}', resto_linea)[0].strip()\n",
    "        \n",
    "        if len(resto_linea) > 2 and not re.match(r'^[\\d\\.]+$', resto_linea):\n",
    "            return limpiar_descripcion(resto_linea)\n",
    "        \n",
    "        # B. Buscar hacia abajo\n",
    "        for offset in range(1, 15):\n",
    "            if start_index + offset >= total_lines: break\n",
    "            next_line = all_lines[start_index + offset].strip()\n",
    "            \n",
    "            if regex_seccion.match(next_line) or regex_capitulo.match(next_line):\n",
    "                return None \n",
    "            \n",
    "            if es_linea_util(next_line):\n",
    "                return limpiar_descripcion(next_line)\n",
    "        return None\n",
    "\n",
    "    # 3. Procesamiento\n",
    "    seccion_actual_romana = \"ND\"\n",
    "\n",
    "    for idx, line in enumerate(all_lines):\n",
    "        match_sec = regex_seccion.match(line)\n",
    "        match_cap = regex_capitulo.match(line)\n",
    "\n",
    "        if match_sec:\n",
    "            num = match_sec.group(1).strip()\n",
    "            seccion_actual_romana = num\n",
    "            desc = buscar_descripcion_real(idx, match_sec)\n",
    "            if desc:\n",
    "                dict_secciones[num] = desc.upper()\n",
    "        \n",
    "        elif match_cap:\n",
    "            num_raw = match_cap.group(1).strip()\n",
    "            key = f\"{int(num_raw):02d}\"\n",
    "            mapa_cap_sec[key] = seccion_actual_romana\n",
    "            desc = buscar_descripcion_real(idx, match_cap)\n",
    "            if desc:\n",
    "                dict_capitulos[key] = desc\n",
    "            else:\n",
    "                dict_capitulos[key] = \"DESCRIPCIÓN NO ENCONTRADA\"\n",
    "\n",
    "    return dict_capitulos, dict_secciones, mapa_cap_sec\n",
    "\n",
    "# Ejecutar Fase 1\n",
    "CAPITULOS_NOMBRES, SECCIONES_NOMBRES, MAPA_CAPITULO_SECCION = generar_catalogos_final(PDF_PATH)\n",
    "print(f\"Catálogos listos: {len(CAPITULOS_NOMBRES)} Capítulos detectados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22744f90",
   "metadata": {},
   "source": [
    "### Fase 2: Extracción de Tablas\n",
    "\n",
    "Una vez que tenemos los catálogos, pasamos a extraer la información del resto del documento.\n",
    "\n",
    "Detección de Área de Interés:\n",
    "\n",
    "- El script itera por cada página buscando la palabra clave \"CÓDIGO\" (el encabezado de la tabla).\n",
    "\n",
    "- Usa la coordenada vertical (bottom) de esa palabra para recortar (crop) la página. Todo lo que esté arriba de ese encabezado (logos, títulos de secretaría) es ignorado para no ensuciar la tabla.\n",
    "\n",
    "Extracción (extract_table):\n",
    "\n",
    "- Se usa la estrategia lines. pdfplumber busca las líneas negras verticales y horizontales para reconstruir la celda de Excel.\n",
    "\n",
    "- Se genera un DataFrame temporal por cada página.\n",
    "\n",
    "Limpieza a Nivel Fila:\n",
    "\n",
    "- Se eliminan filas que sean repeticiones de encabezados (filas que contienen palabras como \"TASA\", \"IMPUESTO\", \"ARANCEL\").\n",
    "\n",
    "- Se eliminan filas de paginación o filas vacías que no contienen códigos ni descripciones útiles.\n",
    "\n",
    "Criterio de Parada:\n",
    "\n",
    "- En cada página, se verifica si el CODIGO_STOP está presente. Si se encuentra, se cortan los datos hasta esa fila y se detiene el bucle de lectura de páginas completamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "COLUMNAS_ESPERADAS = [\"CODIGO\", \"NICO\", \"DESCRIPCION\", \"UNIDAD\", \"IMP_IMP\", \"IMP_EXP\", \"ACOTACION\"]\n",
    "PALABRAS_PROHIBIDAS = [\"SUBP\", \"IMPUESTO\", \"EXP.\", \"IMP.\", \"TASA\", \"CUOTA\", \"TRATADO\", \"ARANCEL\"]\n",
    "stop_process_flag = False\n",
    "\n",
    "print(f\"\\n--- FASE 2: Extracción de tablas de datos ---\")\n",
    "\n",
    "try:\n",
    "    with pdfplumber.open(PDF_PATH) as pdf:\n",
    "        total = len(pdf.pages)\n",
    "        # Empezamos después del índice para acelerar (aprox pág 13), o desde 0 para seguridad\n",
    "        start_page = 0 \n",
    "        \n",
    "        for i in range(start_page, total):\n",
    "            if stop_process_flag: break\n",
    "            page = pdf.pages[i]\n",
    "\n",
    "            # Buscar encabezado de tabla\n",
    "            busqueda = page.search(\"CÓDIGO\")\n",
    "            crop_y = 0\n",
    "            found_header = False\n",
    "\n",
    "            if busqueda:\n",
    "                crop_y = busqueda[0][\"bottom\"] + 2\n",
    "                found_header = True\n",
    "\n",
    "            if found_header:\n",
    "                try:\n",
    "                    cropped_page = page.crop((0, crop_y, page.width, page.height))\n",
    "                    table_settings = {\"vertical_strategy\": \"lines\", \"horizontal_strategy\": \"lines\", \"snap_tolerance\": 4}\n",
    "                    table = cropped_page.extract_table(table_settings)\n",
    "\n",
    "                    if table:\n",
    "                        df = pd.DataFrame(table)\n",
    "                        df = df.dropna(how='all')\n",
    "\n",
    "                        # Limpiar filas basura repetitivas dentro de la tabla\n",
    "                        def es_fila_basura(row):\n",
    "                            texto_fila = \" \".join([str(x) for x in row if x is not None]).upper()\n",
    "                            return any(palabra in texto_fila for palabra in PALABRAS_PROHIBIDAS)\n",
    "\n",
    "                        while not df.empty and es_fila_basura(df.iloc[0]):\n",
    "                            df = df.iloc[1:]\n",
    "                            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                        if df.shape[1] >= 7:\n",
    "                            conteos = df.count()\n",
    "                            indices_top = conteos.nlargest(7).index.sort_values()\n",
    "                            df = df[indices_top]\n",
    "                            df.columns = COLUMNAS_ESPERADAS\n",
    "\n",
    "                            mask_basura = (df['CODIGO'].isna() | (df['CODIGO'] == '')) & \\\n",
    "                                          (df['DESCRIPCION'].str.contains(\"Página\", case=False, na=False))\n",
    "                            df = df[~mask_basura]\n",
    "\n",
    "                            codigos_str = df['CODIGO'].astype(str).str.strip()\n",
    "                            if CODIGO_STOP in codigos_str.values:\n",
    "                                print(f\"¡OBJETIVO ENCONTRADO! Código {CODIGO_STOP} detectado en pág {i+1}.\")\n",
    "                                idx_stop = df[codigos_str == CODIGO_STOP].index[0]\n",
    "                                df = df.iloc[:idx_stop + 1]\n",
    "                                stop_process_flag = True\n",
    "\n",
    "                            all_data.append(df)\n",
    "                except Exception: pass\n",
    "\n",
    "            if i % 50 == 0: print(f\"Procesando página {i+1}/{total}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error abriendo PDF en Fase 2: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8b5cf",
   "metadata": {},
   "source": [
    "### Fase 3: Procesamiento y Lógica Jerárquica\n",
    "\n",
    "Aquí ocurre la transformación de datos crudos a información estructurada.\n",
    "\n",
    "Unificación y Limpieza Inicial:\n",
    "\n",
    "- Se concatenan todas las tablas de todas las páginas en un gran DataFrame maestro.\n",
    "\n",
    "- Se eliminan saltos de línea (\\n) dentro de las celdas para que el texto sea continuo.\n",
    "\n",
    "Lógica de Relleno (Backfill):\n",
    "\n",
    "- En la LIGIE, a veces aparece la descripción de una Partida (ej. \"Caballos\") y en la siguiente fila aparece el código desglosado (\"0101.21.01\"). La fila de \"Caballos\" tiene el código vacío.\n",
    "\n",
    "- Acción: El script usa bfill() (Back Fill). Si una celda de código está vacía, mira hacia abajo, toma el código de la siguiente fila (ej. \"0101.21.01\") y recorta el último par de dígitos. Así, asigna retroactivamente el código padre a la descripción huérfana.\n",
    "\n",
    "Auto-Aprendizaje de Diccionarios:\n",
    "\n",
    "- El script barre todo el DataFrame buscando códigos de longitudes específicas para aprender qué es qué:\n",
    "\n",
    "    - 4 dígitos = Partida.\n",
    "\n",
    "    - 5 dígitos = Desdoblamiento (Nivel intermedio).\n",
    "\n",
    "    - 6 dígitos = Subpartida.\n",
    "\n",
    "- Guarda estas descripciones en nuevos diccionarios para usarlos más tarde en la concatenación.\n",
    "\n",
    "Filtrado de \"Hojas\" (Nivel Fracción):\n",
    "\n",
    "- Se filtra el DataFrame para quedarse únicamente con los registros finales: aquellos que tienen 8 dígitos y una Tasa de Impuesto definida. Esto elimina los encabezados intermedios (que ya guardamos en diccionarios) y deja solo los productos importables.\n",
    "\n",
    "Desglose y Mapeo (Enriquecimiento):\n",
    "\n",
    "- Desglose: Se separa el código \"01020304\" en columnas individuales: Show_Capitulo (\"01\"), Show_Partida (\"02\"), Show_Desdoblamiento (\"0\"), Show_Subpartida (\"3\"), etc.\n",
    "\n",
    "- Mapeo de Texto: Usando los diccionarios creados en la Fase 1 y Fase 3, se crea una columna de texto para cada nivel.\n",
    "\n",
    "    - Ejemplo: La columna Txt_Capitulo busca \"01\" en el diccionario y devuelve \"Animales Vivos.\".\n",
    "\n",
    "    - Homogenización: Se aplica formato de texto: Primera letra mayúscula (Capitalize) y se asegura que todos terminen en punto final.\n",
    "\n",
    "Concatenación de Texto:\n",
    "\n",
    "- Se crea la columna Texto_Concatenado. El script toma todos los textos jerárquicos (Sección, Capítulo, Partida, Desdoblamiento, Subpartida, Fracción).\n",
    "\n",
    "- Une estos textos usando un espacio simple. Al tener puntuación asegurada en el paso anterior, el resultado es una oración fluida y legible.\n",
    "\n",
    "### Fase 4: Exportación (Excel)\n",
    "\n",
    "La etapa final es verter los datos procesados en un archivo .xlsx ordenado y formateado.\n",
    "\n",
    "Creación de Paneles (Sub-tablas):\n",
    "\n",
    "- Se crean 4 DataFrames derivados con distintas columnas según la necesidad:\n",
    "\n",
    "    - LIGIE: Datos crudos procesados.\n",
    "\n",
    "    - Reducido: Enfoque numérico (Códigos desglosados y tasas).\n",
    "\n",
    "    - Textual: Enfoque descriptivo (Nombres de niveles y tasas).\n",
    "\n",
    "    - Extendido: La matriz completa (Números + Nombres).\n",
    "\n",
    "    - Concatenado: Código completo + Descripción unificada.\n",
    "\n",
    "Motor de Excel (xlsxwriter):\n",
    "\n",
    "- Se inicia el motor de escritura de Excel.\n",
    "\n",
    "Estilizado Inteligente:\n",
    "\n",
    "- Se definen formatos: Encabezados en azul y negrita, bordes en todas las celdas.\n",
    "\n",
    "- Wrap Text (Ajuste de texto): Se aplica condicionalmente. Si la columna contiene descripciones largas o la columna \"ACOTACION\", se activa el ajuste de línea para que el texto no se desborde ni se oculte.\n",
    "\n",
    "Ajuste de Anchos:\n",
    "\n",
    "- Columnas de códigos (ej. \"Capítulo\"): Ancho 8 (angosto).\n",
    "\n",
    "- Columnas de texto (ej. \"Descripción\"): Ancho 50 (amplio).\n",
    "\n",
    "- Resto de columnas: Ancho 12 (estándar).\n",
    "\n",
    "- Escritura: Se guardan las 5 pestañas y se cierra el archivo, finalizando el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_data:\n",
    "    print(\"\\n--- FASE 3: Procesamiento y Exportación ---\")\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    final_df = final_df.replace(r'\\n', ' ', regex=True)\n",
    "\n",
    "    # 1. Relleno Jerárquico\n",
    "    print(\"Aplicando relleno de códigos...\")\n",
    "    final_df['NICO'] = final_df['NICO'].fillna('').astype(str).str.strip().replace(['--', '-'], '')\n",
    "    final_df['CODIGO'] = final_df['CODIGO'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    \n",
    "    siguientes_codigos = final_df['CODIGO'].bfill()\n",
    "    cond_codigo_vacio = final_df['CODIGO'].isna()\n",
    "    cond_nico_vacio = final_df['NICO'] == ''\n",
    "    mascara = cond_codigo_vacio & cond_nico_vacio\n",
    "    \n",
    "    if not siguientes_codigos[mascara].empty:\n",
    "        final_df.loc[mascara, 'CODIGO'] = siguientes_codigos[mascara].astype(str).str[:-1]\n",
    "\n",
    "    final_df = final_df.fillna('')\n",
    "\n",
    "    # 2. Generación de Diccionarios (Partida, Desdoblamiento, Subpartida)\n",
    "    print(\"Extrayendo descripciones jerárquicas...\")\n",
    "    panel_base = final_df.copy()\n",
    "    panel_base['CODIGO_LIMPIO'] = panel_base['CODIGO'].astype(str).str.replace('.', '', regex=False).str.strip()\n",
    "\n",
    "    dict_partidas = {}       # 4 dígitos\n",
    "    dict_desdoblamiento = {} # 5 dígitos\n",
    "    dict_subpartidas = {}    # 6 dígitos\n",
    "\n",
    "    for row in panel_base.itertuples():\n",
    "        code = getattr(row, 'CODIGO_LIMPIO', '')\n",
    "        desc = getattr(row, 'DESCRIPCION', '')\n",
    "        \n",
    "        if len(code) == 4:\n",
    "            dict_partidas[code] = desc\n",
    "        elif len(code) == 5:\n",
    "            dict_desdoblamiento[code] = desc\n",
    "        elif len(code) == 6:\n",
    "            dict_subpartidas[code] = desc\n",
    "\n",
    "    # 3. Filtrado Final (Solo filas de producto final)\n",
    "    panel_df = panel_base[\n",
    "        (panel_base['CODIGO_LIMPIO'].str.len() == 8) &\n",
    "        (panel_base['IMP_IMP'].str.strip() != '')\n",
    "    ].copy()\n",
    "    \n",
    "    panel_df = panel_df.drop_duplicates(subset=['CODIGO', 'NICO'], keep='first')\n",
    "\n",
    "    # 4. Desglose de Dígitos (Columnas numéricas \"Show_\")\n",
    "    print(\"Desglosando dígitos...\")\n",
    "    code_full = panel_df['CODIGO_LIMPIO']\n",
    "    \n",
    "    panel_df['Show_Capitulo']       = code_full.str[:2]\n",
    "    panel_df['Show_Partida']        = code_full.str[2:4]\n",
    "    panel_df['Show_Desdoblamiento'] = code_full.str[4:5]\n",
    "    panel_df['Show_Subpartida']     = code_full.str[5:6]\n",
    "    panel_df['Show_Fraccion']       = code_full.str[6:8]\n",
    "\n",
    "    # 5. Mapeo de Textos\n",
    "    def get_seccion_romana(cap_code):\n",
    "        return MAPA_CAPITULO_SECCION.get(cap_code, \"ND\")\n",
    "\n",
    "    panel_df['Txt_Seccion_Romana'] = code_full.str[:2].apply(get_seccion_romana)\n",
    "    \n",
    "    panel_df['Txt_Seccion_Nombre'] = panel_df['Txt_Seccion_Romana'].map(SECCIONES_NOMBRES)\n",
    "    panel_df['Txt_Capitulo']       = code_full.str[:2].map(CAPITULOS_NOMBRES)\n",
    "    panel_df['Txt_Partida']        = code_full.str[:4].map(dict_partidas)\n",
    "    panel_df['Txt_Desdoblamiento'] = code_full.str[:5].map(dict_desdoblamiento)\n",
    "    panel_df['Txt_Subpartida']     = code_full.str[:6].map(dict_subpartidas)\n",
    "\n",
    "    # 6. Homogenización de Formatos de Texto\n",
    "    print(\"Formateando textos (Mayúsculas y Puntos)...\")\n",
    "    \n",
    "    # Sección: Capitalize + Punto\n",
    "    panel_df['Txt_Seccion_Nombre'] = panel_df['Txt_Seccion_Nombre'].fillna('').astype(str).str.lower().str.capitalize()\n",
    "    panel_df['Txt_Seccion_Nombre'] = panel_df['Txt_Seccion_Nombre'].str.rstrip('.') + '.'\n",
    "    \n",
    "    # Capítulo: Asegurar punto final\n",
    "    panel_df['Txt_Capitulo'] = panel_df['Txt_Capitulo'].fillna('').astype(str).str.rstrip('.') + '.'\n",
    "\n",
    "    panel_df['Codigo_Completo'] = panel_df['CODIGO']\n",
    "\n",
    "    # 7. Concatenación (Sin PIPES, solo espacio)\n",
    "    print(\"Generando concatenación limpia...\")\n",
    "    \n",
    "    def concatenar_descripciones(row):\n",
    "        items = [\n",
    "            row['Txt_Seccion_Nombre'],\n",
    "            row['Txt_Capitulo'],\n",
    "            row['Txt_Partida'],\n",
    "            row['Txt_Desdoblamiento'],\n",
    "            row['Txt_Subpartida'],\n",
    "            row['DESCRIPCION']\n",
    "        ]\n",
    "        # Unir con espacio simple. Filtra vacíos y 'nan'.\n",
    "        return \" \".join([str(x).strip() for x in items if str(x).strip() != '' and str(x).strip() != 'nan'])\n",
    "\n",
    "    panel_df['Texto_Concatenado'] = panel_df.apply(concatenar_descripciones, axis=1)\n",
    "\n",
    "    # --- DEFINICIÓN DE ESTRUCTURAS DE SALIDA ---\n",
    "\n",
    "    # Panel Reducido\n",
    "    cols_reducido = [\n",
    "        'Codigo_Completo', 'Txt_Seccion_Romana', \n",
    "        'Show_Capitulo', 'Show_Partida', 'Show_Desdoblamiento', 'Show_Subpartida', 'Show_Fraccion', \n",
    "        'UNIDAD', 'IMP_IMP', 'IMP_EXP'\n",
    "    ]\n",
    "    df_reducido = panel_df[cols_reducido].copy()\n",
    "    df_reducido.columns = [\n",
    "        'Código Completo', 'Sección', \n",
    "        'Capítulo', 'Partida', 'Desdoblamiento', 'Subpartida', 'Fracción', \n",
    "        'Unidad', 'Imp. Imp.', 'Imp. Exp.'\n",
    "    ]\n",
    "\n",
    "    # Panel Textual\n",
    "    cols_textual = [\n",
    "        'Codigo_Completo', \n",
    "        'Txt_Seccion_Nombre', 'Txt_Capitulo', 'Txt_Partida', \n",
    "        'Txt_Desdoblamiento', 'Txt_Subpartida', \n",
    "        'DESCRIPCION', \n",
    "        'UNIDAD', 'IMP_IMP', 'IMP_EXP'\n",
    "    ]\n",
    "    df_textual = panel_df[cols_textual].copy()\n",
    "    df_textual.columns = [\n",
    "        'Código Completo', \n",
    "        'Nombre Sección', 'Nombre Capítulo', 'Nombre Partida', \n",
    "        'Nombre Desdoblamiento', 'Nombre Subpartida', \n",
    "        'Descripción Fracción', \n",
    "        'Unidad', 'Imp. Imp.', 'Imp. Exp.'\n",
    "    ]\n",
    "\n",
    "    # Panel Extendido\n",
    "    cols_extendido = [\n",
    "        'Codigo_Completo', \n",
    "        'Txt_Seccion_Romana', 'Txt_Seccion_Nombre',\n",
    "        'Show_Capitulo', 'Txt_Capitulo',\n",
    "        'Show_Partida', 'Txt_Partida',\n",
    "        'Show_Desdoblamiento', 'Txt_Desdoblamiento', \n",
    "        'Show_Subpartida', 'Txt_Subpartida',\n",
    "        'Show_Fraccion', \n",
    "        'DESCRIPCION',   \n",
    "        'UNIDAD', 'IMP_IMP', 'IMP_EXP'\n",
    "    ]\n",
    "    df_extendido = panel_df[cols_extendido].copy()\n",
    "    df_extendido.columns = [\n",
    "        'Código Completo', \n",
    "        'Sección', 'Nombre Sección', \n",
    "        'Capítulo', 'Nombre Capítulo',\n",
    "        'Partida', 'Nombre Partida',\n",
    "        'Desdob.', 'Nombre Desdoblamiento',\n",
    "        'Subpartida', 'Nombre Subpartida',\n",
    "        'Fracción', \n",
    "        'Descripción Fracción',\n",
    "        'Unidad', 'Imp. Imp.', 'Imp. Exp.'\n",
    "    ]\n",
    "\n",
    "    # Panel Concatenado\n",
    "    cols_concat = ['Codigo_Completo', 'Texto_Concatenado', 'UNIDAD', 'IMP_IMP', 'IMP_EXP']\n",
    "    df_concatenado = panel_df[cols_concat].copy()\n",
    "    df_concatenado.columns = ['Código Completo', 'Descripción Completa Concatenada', 'Unidad', 'Imp. Imp.', 'Imp. Exp.']\n",
    "\n",
    "    # --- EXPORTACIÓN A EXCEL ---\n",
    "    nombre_salida = \"LIGIE_Maestra_Unificada.xlsx\"\n",
    "    print(f\"Generando archivo Excel: {nombre_salida} ...\")\n",
    "\n",
    "    writer = pd.ExcelWriter(nombre_salida, engine='xlsxwriter')\n",
    "    workbook = writer.book\n",
    "\n",
    "    # Formatos\n",
    "    fmt_header = workbook.add_format({'bold': True, 'border': 1, 'bg_color': '#D9E1F2', 'valign': 'top', 'align': 'center', 'font_name': 'Arial', 'font_size': 10})\n",
    "    fmt_normal = workbook.add_format({'border': 1, 'valign': 'top', 'font_name': 'Arial', 'font_size': 9})\n",
    "    fmt_wrap = workbook.add_format({'border': 1, 'valign': 'top', 'text_wrap': True, 'font_name': 'Arial', 'font_size': 9})\n",
    "\n",
    "    def escribir_hoja(dataframe, nombre_hoja):\n",
    "        worksheet = workbook.add_worksheet(nombre_hoja)\n",
    "        writer.sheets[nombre_hoja] = worksheet\n",
    "        \n",
    "        headers = dataframe.columns.tolist()\n",
    "        for col_idx, header in enumerate(headers):\n",
    "            worksheet.write(0, col_idx, header, fmt_header)\n",
    "            \n",
    "        for row_idx, row in enumerate(dataframe.itertuples(index=False), start=1):\n",
    "            for col_idx, value in enumerate(row):\n",
    "                header_name = headers[col_idx]\n",
    "                \n",
    "                # Columnas con Wrap Text: Descripciones, Nombres, Acotación y Concatenada\n",
    "                columnas_largas = [\"Nombre\", \"DESCRIPCION\", \"Descripción\", \"ACOTACION\", \"Concatenada\"]\n",
    "                es_texto_largo = any(x in header_name for x in columnas_largas)\n",
    "                \n",
    "                formato = fmt_wrap if es_texto_largo else fmt_normal\n",
    "                if pd.isna(value): value = \"\"\n",
    "                worksheet.write(row_idx, col_idx, value, formato)\n",
    "        \n",
    "        # Ajuste inteligente de anchos\n",
    "        for idx, col_name in enumerate(headers):\n",
    "            # Columnas de códigos cortos\n",
    "            if col_name in ['Capítulo', 'Partida', 'Desdob.', 'Desdoblamiento', 'Subpartida', 'Fracción', 'Sección']:\n",
    "                 worksheet.set_column(idx, idx, 8) \n",
    "            # Columnas de texto largo\n",
    "            elif any(x in col_name for x in [\"Nombre\", \"DESCRIPCION\", \"Descripción\", \"ACOTACION\", \"Concatenada\"]):\n",
    "                worksheet.set_column(idx, idx, 50) \n",
    "            # Resto (Unidad, Tasas, Código Completo)\n",
    "            else:\n",
    "                worksheet.set_column(idx, idx, 12)\n",
    "\n",
    "    # Escritura de Hojas\n",
    "    escribir_hoja(final_df, \"LIGIE\") \n",
    "    escribir_hoja(df_reducido, \"Panel Reducido\")\n",
    "    escribir_hoja(df_textual, \"Panel Textual\")\n",
    "    escribir_hoja(df_extendido, \"Panel Extendido\")\n",
    "    escribir_hoja(df_concatenado, \"Concatenado\")\n",
    "\n",
    "    writer.close()\n",
    "    print(\"¡PROCESO FINALIZADO CON ÉXITO!\")\n",
    "\n",
    "else:\n",
    "    print(\"No se encontraron datos para exportar. Verifica el archivo PDF.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
