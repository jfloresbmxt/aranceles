{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a78228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01cc4de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO PROCESAMIENTO HTS (CON SECCIONES) ---\n",
      "Referencia LIGIE: C:/Users/Edward/Desktop/Bancomext/Tariffs/data/intermediate/LIGIE_Maestra_Unificada.xlsx\n",
      "Datos HTS Input:  C:/Users/Edward/Desktop/Bancomext/Tariffs/data/raw/htsdata.csv\n",
      "Archivo Salida:   C:/Users/Edward/Desktop/Bancomext/Tariffs/data/intermediate/HTS_Procesada_Final.xlsx\n",
      "--------------------------------------------------\n",
      ">> Cargando referencias LIGIE y mapeando Secciones...\n",
      "   Diccionarios listos.\n",
      ">> Procesando HTS...\n",
      ">> Normalizando códigos HTS...\n",
      ">> Guardando Excel: C:/Users/Edward/Desktop/Bancomext/Tariffs/data/intermediate/HTS_Procesada_Final.xlsx\n",
      "¡PROCESO FINALIZADO EXITOSAMENTE!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ==========================================\n",
    "# 0. CONFIGURACIÓN DE RUTAS\n",
    "# ==========================================\n",
    "PATH_LIGIE = r\"C:/Users/Edward/Desktop/Bancomext/Tariffs/data/intermediate/LIGIE_Maestra_Unificada.xlsx\"\n",
    "PATH_HTS_INPUT = r\"C:/Users/Edward/Desktop/Bancomext/Tariffs/data/raw/htsdata.csv\"\n",
    "PATH_OUTPUT = r\"C:/Users/Edward/Desktop/Bancomext/Tariffs/data/intermediate/HTS_Procesada_Final.xlsx\"\n",
    "\n",
    "print(\"--- INICIANDO PROCESAMIENTO HTS (CON SECCIONES) ---\")\n",
    "print(f\"Referencia LIGIE: {PATH_LIGIE}\")\n",
    "print(f\"Datos HTS Input:  {PATH_HTS_INPUT}\")\n",
    "print(f\"Archivo Salida:   {PATH_OUTPUT}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ==========================================\n",
    "# FUNCIONES AUXILIARES\n",
    "# ==========================================\n",
    "\n",
    "def forzar_dos_digitos(serie):\n",
    "    return serie.fillna('').astype(str).str.replace(r'\\.0$', '', regex=True).str.strip().str.zfill(2)\n",
    "\n",
    "def forzar_un_digito(serie):\n",
    "    return serie.fillna('').astype(str).str.replace(r'\\.0$', '', regex=True).str.strip().str.zfill(1)\n",
    "\n",
    "def formatear_hts_con_puntos(code_clean):\n",
    "    if len(code_clean) != 8:\n",
    "        return code_clean \n",
    "    return f\"{code_clean[:4]}.{code_clean[4:6]}.{code_clean[6:8]}\"\n",
    "\n",
    "def limpiar_y_normalizar_hts(code):\n",
    "    c = str(code).replace('.', '').strip()\n",
    "    if len(c) % 2 != 0: c = '0' + c\n",
    "    if len(c) >= 10: c = c[:8]\n",
    "    return c\n",
    "\n",
    "# ==========================================\n",
    "# FASE 1: CARGAR DICCIONARIOS LIGIE (INCLUYENDO SECCIÓN)\n",
    "# ==========================================\n",
    "\n",
    "def cargar_diccionarios_ligie(path):\n",
    "    if not os.path.exists(path):\n",
    "        sys.exit(f\"ERROR: No existe {path}\")\n",
    "\n",
    "    print(\">> Cargando referencias LIGIE y mapeando Secciones...\")\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=\"Panel Extendido\", dtype=str)\n",
    "        \n",
    "        # Recuperar componentes clave\n",
    "        df['Ref_Cap'] = forzar_dos_digitos(df['Capítulo'])      \n",
    "        df['Ref_Part_Suffix'] = forzar_dos_digitos(df['Partida']) \n",
    "        df['Ref_Desdob'] = forzar_un_digito(df['Desdob.'])      \n",
    "        df['Ref_Sub'] = forzar_un_digito(df['Subpartida'])      \n",
    "\n",
    "        # Construir Llaves\n",
    "        df['Key_Cap'] = df['Ref_Cap']\n",
    "        df['Key_Part'] = df['Ref_Cap'] + df['Ref_Part_Suffix']\n",
    "        df['Key_Sub'] = df['Key_Part'] + \".\" + df['Ref_Desdob'] + df['Ref_Sub']\n",
    "        \n",
    "        # --- NUEVO: DICCIONARIOS DE SECCIÓN ---\n",
    "        # Como cada Capítulo pertenece a una única Sección, creamos un df auxiliar único por capítulo\n",
    "        df_caps = df[['Ref_Cap', 'Sección', 'Nombre Sección']].drop_duplicates(subset=['Ref_Cap'])\n",
    "        \n",
    "        ref_sec_rom = pd.Series(df_caps['Sección'].values, index=df_caps['Ref_Cap']).to_dict()\n",
    "        ref_sec_nom = pd.Series(df_caps['Nombre Sección'].values, index=df_caps['Ref_Cap']).to_dict()\n",
    "\n",
    "        # --- DICCIONARIOS ESTÁNDAR ---\n",
    "        ref_cap = pd.Series(df['Nombre Capítulo'].values, index=df['Key_Cap']).to_dict()\n",
    "        ref_part = pd.Series(df['Nombre Partida'].values, index=df['Key_Part']).to_dict()\n",
    "        ref_subpart = pd.Series(df['Nombre Subpartida'].values, index=df['Key_Sub']).to_dict()\n",
    "        ref_desdob_name = pd.Series(df['Nombre Desdoblamiento'].values, index=df['Key_Sub']).to_dict()\n",
    "\n",
    "        print(\"   Diccionarios listos.\")\n",
    "        return ref_sec_rom, ref_sec_nom, ref_cap, ref_part, ref_subpart, ref_desdob_name\n",
    "\n",
    "    except Exception as e:\n",
    "        sys.exit(f\"ERROR leyendo LIGIE: {e}\")\n",
    "\n",
    "REF_SEC_ROM, REF_SEC_NOM, REF_CAP, REF_PART, REF_SUB, REF_DESDOB = cargar_diccionarios_ligie(PATH_LIGIE)\n",
    "\n",
    "# ==========================================\n",
    "# FASE 2: LIMPIEZA INICIAL HTS\n",
    "# ==========================================\n",
    "\n",
    "def limpiar_hts_inicial(path):\n",
    "    if not os.path.exists(path):\n",
    "        sys.exit(f\"ERROR: No existe {path}\")\n",
    "    \n",
    "    print(\">> Procesando HTS...\")\n",
    "    try:\n",
    "        if path.endswith('.csv'):\n",
    "            df = pd.read_csv(path, dtype=str)\n",
    "        else:\n",
    "            df = pd.read_excel(path, dtype=str)\n",
    "    except:\n",
    "        sys.exit(\"No se pudo leer el archivo.\")\n",
    "\n",
    "    cols = [\"HTS Number\", \"Description\", \"Unit of Quantity\", \"General Rate of Duty\", \"Special Rate of Duty\"]\n",
    "    df = df[cols].copy().fillna('')\n",
    "    \n",
    "    # Columna temporal\n",
    "    df['HTS_Clean_Temp'] = df['HTS Number'].str.replace('.', '', regex=False).str.strip()\n",
    "    \n",
    "    # Corte 99\n",
    "    mask_99 = df['HTS_Clean_Temp'].str.startswith('99', na=False)\n",
    "    if mask_99.any():\n",
    "        idx = df[mask_99].index[0]\n",
    "        df = df.iloc[:idx].copy()\n",
    "    \n",
    "    # Eliminar temporal\n",
    "    df = df.drop(columns=['HTS_Clean_Temp'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "DF_HTS_CLEAN = limpiar_hts_inicial(PATH_HTS_INPUT)\n",
    "\n",
    "# ==========================================\n",
    "# FASE 3: PREPARACIÓN Y NORMALIZACIÓN\n",
    "# ==========================================\n",
    "print(\">> Normalizando códigos HTS...\")\n",
    "\n",
    "df_panels = DF_HTS_CLEAN[DF_HTS_CLEAN['General Rate of Duty'] != ''].copy()\n",
    "df_panels['HTS_8_Clean'] = df_panels['HTS Number'].apply(limpiar_y_normalizar_hts)\n",
    "df_panels['HTS_Dotted'] = df_panels['HTS_8_Clean'].apply(formatear_hts_con_puntos)\n",
    "\n",
    "# ==========================================\n",
    "# FASE 4: CONSTRUCCIÓN DE PANELES\n",
    "# ==========================================\n",
    "\n",
    "clean = df_panels['HTS_8_Clean'] \n",
    "dotted = df_panels['HTS_Dotted'] \n",
    "\n",
    "# Claves para mapeo\n",
    "key_cap = clean.str[:2]\n",
    "key_part = clean.str[:4]\n",
    "key_sub = clean.str[:4] + \".\" + clean.str[4:6]\n",
    "\n",
    "# --- A. PANEL NUMÉRICO ---\n",
    "df_num = pd.DataFrame()\n",
    "df_num['Código']   = dotted\n",
    "# Agregamos Sección (Romana) consultando por capítulo\n",
    "df_num['Sección']  = key_cap.map(REF_SEC_ROM).fillna('') \n",
    "df_num['Capítulo'] = clean.str[:2]\n",
    "df_num['Partida']  = clean.str[2:4]\n",
    "df_num['Desdoblamiento'] = clean.str[4:5]\n",
    "df_num['Subpartida']     = clean.str[5:6]\n",
    "df_num['Fracción']       = clean.str[6:8]\n",
    "df_num['Unit of Quantity'] = df_panels['Unit of Quantity']\n",
    "df_num['General Rate of Duty'] = df_panels['General Rate of Duty']\n",
    "\n",
    "# --- B. PANEL TEXTUAL ---\n",
    "df_txt = pd.DataFrame()\n",
    "df_txt['Código'] = dotted\n",
    "# Agregamos Nombre Sección\n",
    "df_txt['Nombre Sección'] = key_cap.map(REF_SEC_NOM).fillna('')\n",
    "df_txt['Nombre Capítulo'] = key_cap.map(REF_CAP).fillna('')\n",
    "df_txt['Nombre Partida']  = key_part.map(REF_PART).fillna('')\n",
    "df_txt['Nombre Desdoblamiento'] = key_sub.map(REF_DESDOB).fillna('')\n",
    "df_txt['Nombre Subpartida']     = key_sub.map(REF_SUB).fillna('')\n",
    "df_txt['Descripción Fracción'] = df_panels['Description']\n",
    "df_txt['Unit of Quantity'] = df_panels['Unit of Quantity']\n",
    "df_txt['General Rate of Duty'] = df_panels['General Rate of Duty']\n",
    "\n",
    "# --- C. PANEL EXTENDIDO ---\n",
    "df_ext = pd.DataFrame()\n",
    "df_ext['Código'] = dotted\n",
    "\n",
    "# Sección\n",
    "df_ext['Sección'] = df_num['Sección']\n",
    "df_ext['Nombre Sección'] = df_txt['Nombre Sección']\n",
    "\n",
    "# Capítulo\n",
    "df_ext['Capítulo']        = df_num['Capítulo']\n",
    "df_ext['Nombre Capítulo'] = df_txt['Nombre Capítulo']\n",
    "\n",
    "# Partida\n",
    "df_ext['Partida']        = df_num['Partida']\n",
    "df_ext['Nombre Partida'] = df_txt['Nombre Partida']\n",
    "\n",
    "# Desdoblamiento\n",
    "df_ext['Desdoblamiento'] = df_num['Desdoblamiento']\n",
    "df_ext['Nombre Desdoblamiento'] = df_txt['Nombre Desdoblamiento']\n",
    "\n",
    "# Subpartida\n",
    "df_ext['Subpartida']     = df_num['Subpartida']\n",
    "df_ext['Nombre Subpartida'] = df_txt['Nombre Subpartida']\n",
    "\n",
    "# Fracción\n",
    "df_ext['Fracción']             = df_num['Fracción']\n",
    "df_ext['Descripción Fracción'] = df_txt['Descripción Fracción']\n",
    "\n",
    "df_ext['Unit of Quantity']     = df_panels['Unit of Quantity']\n",
    "df_ext['General Rate of Duty'] = df_panels['General Rate of Duty']\n",
    "\n",
    "# --- D. PANEL CONCATENADO ---\n",
    "df_concat = pd.DataFrame()\n",
    "df_concat['Código'] = dotted\n",
    "\n",
    "def concatenar(row):\n",
    "    partes = [\n",
    "        row['Nombre Sección'],  # Ahora incluimos la Sección al inicio\n",
    "        row['Nombre Capítulo'],\n",
    "        row['Nombre Partida'],\n",
    "        row['Nombre Desdoblamiento'],\n",
    "        row['Nombre Subpartida'],\n",
    "        row['Descripción Fracción']\n",
    "    ]\n",
    "    validas = [str(x).strip() for x in partes if str(x).strip() not in ['', 'ND', 'nan']]\n",
    "    return \" \".join(validas)\n",
    "\n",
    "df_concat['Descripción Completa'] = df_txt.apply(concatenar, axis=1)\n",
    "df_concat['Unit of Quantity']     = df_panels['Unit of Quantity']\n",
    "df_concat['General Rate of Duty'] = df_panels['General Rate of Duty']\n",
    "\n",
    "# ==========================================\n",
    "# FASE 5: EXPORTACIÓN CON FORMATO AVANZADO\n",
    "# ==========================================\n",
    "print(f\">> Guardando Excel: {PATH_OUTPUT}\")\n",
    "\n",
    "try:\n",
    "    writer = pd.ExcelWriter(PATH_OUTPUT, engine='xlsxwriter')\n",
    "    workbook = writer.book\n",
    "\n",
    "    # Estilos\n",
    "    fmt_header = workbook.add_format({\n",
    "        'bold': True, 'border': 1, 'bg_color': '#BDD7EE',\n",
    "        'valign': 'vcenter', 'align': 'center', 'font_name': 'Arial', 'font_size': 10, 'text_wrap': True\n",
    "    })\n",
    "    fmt_body = workbook.add_format({'border': 1, 'valign': 'top', 'font_name': 'Arial', 'font_size': 9})\n",
    "    fmt_wrap = workbook.add_format({'border': 1, 'valign': 'top', 'font_name': 'Arial', 'font_size': 9, 'text_wrap': True})\n",
    "\n",
    "    def escribir_hoja(df, nombre):\n",
    "        df.to_excel(writer, sheet_name=nombre, index=False, startrow=1, header=False)\n",
    "        ws = writer.sheets[nombre]\n",
    "        \n",
    "        # Headers\n",
    "        for idx, col in enumerate(df.columns):\n",
    "            ws.write(0, idx, col, fmt_header)\n",
    "            \n",
    "        # Determinar Ancho de Columnas de Texto según la Hoja\n",
    "        if \"Textual\" in nombre or \"Extendido\" in nombre:\n",
    "            ancho_texto = 37 \n",
    "        else:\n",
    "            ancho_texto = 50 \n",
    "\n",
    "        # Cuerpo\n",
    "        for col_idx, col_name in enumerate(df.columns):\n",
    "            # Detectar columnas texto largo + Special Rate\n",
    "            columnas_wrap = [\"Description\", \"Descripción\", \"Nombre\", \"Completa\", \"Special Rate\"]\n",
    "            es_largo = any(x in col_name for x in columnas_wrap)\n",
    "            \n",
    "            estilo = fmt_wrap if es_largo else fmt_body\n",
    "            \n",
    "            # Escritura celda por celda\n",
    "            for row_idx in range(len(df)):\n",
    "                val = df.iloc[row_idx, col_idx]\n",
    "                if pd.isna(val): val = \"\"\n",
    "                ws.write(row_idx + 1, col_idx, val, estilo)\n",
    "            \n",
    "            # Ajustar Anchos\n",
    "            if es_largo:\n",
    "                ws.set_column(col_idx, col_idx, ancho_texto)\n",
    "            elif \"General Rate\" in col_name:\n",
    "                ws.set_column(col_idx, col_idx, 15)\n",
    "            elif len(col_name) <= 10 and \"Unit\" not in col_name: \n",
    "                ws.set_column(col_idx, col_idx, 10)\n",
    "            else:\n",
    "                ws.set_column(col_idx, col_idx, 12)\n",
    "\n",
    "    escribir_hoja(DF_HTS_CLEAN, \"HTS Cleaned\")\n",
    "    escribir_hoja(df_num, \"Panel Numérico\")\n",
    "    escribir_hoja(df_txt, \"Panel Textual\")\n",
    "    escribir_hoja(df_ext, \"Panel Extendido\")\n",
    "    escribir_hoja(df_concat, \"Concatenado\")\n",
    "\n",
    "    writer.close()\n",
    "    print(\"¡PROCESO FINALIZADO EXITOSAMENTE!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f94f99",
   "metadata": {},
   "source": [
    "Debemos hacer un archivo markdown con un formato y estructura similar al de la LIGIE, únicamente tomando este script como referencia, pero tomando en cuenta las mismas prácticas consideradas para las funciones y sus nombres, así como la explicación individual de cada función. La idea es tomar la manera en que se documentó el archivo de la LIGIE y aplicar esa lógica a este."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
