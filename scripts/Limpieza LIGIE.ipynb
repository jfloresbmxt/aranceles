{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6d759b",
   "metadata": {},
   "source": [
    "# Limpieza LIGIE\n",
    "## Fases de Tratado\n",
    "### Fase 0: Configuración General\n",
    "\n",
    "Antes de iniciar cualquier lógica, es fundamental preparar el entorno de ejecución instalando las dependencias necesarias y comprendiendo las herramientas que manipularán el archivo PDF y las estructuras de datos.\n",
    "\n",
    "    Instalación de dependencias: Para asegurar que el script funcione correctamente, se deben instalar las librerías externas que no vienen incluidas por defecto en Python. Ejecuta el siguiente comando en tu terminal o en una celda de tu entorno de desarrollo:\n",
    "\n",
    "        pip install pdfplumber pandas numpy xlsxwriter\n",
    "\n",
    "    Librerías:\n",
    "\n",
    "        pdfplumber: Es el motor principal de extracción. Se elige sobre otras opciones (como PyPDF2) porque permite estrategias visuales (detección de líneas de tablas) y lectura de texto posicional precisa.\n",
    "\n",
    "        pandas: Utilizada para crear los DataFrames. Es vital para manipular filas, columnas, rellenar datos faltantes (NaN) y transformar texto masivamente.\n",
    "\n",
    "        numpy (np): Se usa auxiliarmente para definir valores nulos (np.nan) que pandas pueda reconocer y tratar.\n",
    "\n",
    "        re: Librería de Expresiones Regulares. Es el \"cerebro\" que identifica patrones de texto complejos (ej. detectar si una línea empieza con \"Sección IV\" o \"Capítulo 85\").\n",
    "\n",
    "        os: Utilidad de sistema operativo para manejo de rutas de archivos.\n",
    "\n",
    "    Variables Globales:\n",
    "\n",
    "        os.chdir(''): Define el directorio de trabajo.\n",
    "\n",
    "        PDF_PATH: Define la ruta del archivo origen.\n",
    "\n",
    "        CODIGO_STOP: El script dejará de leer el PDF cuando encuentre este código específico (9807.00.01), optimizando tiempo al evitar leer anexos irrelevantes al final del documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0947e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pdfplumber pandas numpy xlsxwriter\n",
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "#os.chdir('C:/Users/M20537/Downloads')\n",
    "PDF_PATH = \"LIGIE-UNIFICADA-LIGIE_20250728-20250728.pdf\"\n",
    "CODIGO_STOP = \"9807.00.01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f81d8",
   "metadata": {},
   "source": [
    "### Fase 1: Generación de Catálogos\n",
    "\n",
    "Esta es la fase más compleja de lógica de texto. Su objetivo es leer el índice inicial del PDF para entender qué significa \"Capítulo 01\" o \"Sección V\", resolviendo el problema de que los títulos se cortan entre páginas.\n",
    "\n",
    "    Lectura Masiva:\n",
    "\n",
    "        En lugar de procesar página por página, el script lee las primeras N páginas (configurado a 25) y extrae todo el texto.\n",
    "\n",
    "        Acción: Convierte todas las páginas en una lista única y continua de líneas de texto (all_lines).\n",
    "\n",
    "        Propósito: Eliminar la noción de \"salto de página\". Para el código, la línea final de la página 3 y la primera de la página 4 son contiguas.\n",
    "\n",
    "    Filtrado de \"Basura\" (es_linea_util):\n",
    "\n",
    "        Se define una lista negra (TEXTOS_BASURA) con encabezados recurrentes (\"Secretaría de Economía\", \"Dirección General...\", \"Página\", etc.).\n",
    "\n",
    "        El script descarta cualquier línea que contenga estas frases, sea solo numérica (números de página) o sea demasiado corta. Esto limpia el \"ruido\" visual del PDF.\n",
    "\n",
    "    Búsqueda \"Lookahead\" (Mirar hacia adelante):\n",
    "\n",
    "        El script recorre la lista de líneas buscando patrones Regex de Sección [Romano] o Capítulo [Arábigo].\n",
    "\n",
    "        Al encontrar uno (ej. \"Capítulo 41\"), busca su descripción.\n",
    "\n",
    "        Lógica Crítica: Si la descripción no está en la misma línea, el script entra en un bucle que revisa las siguientes 15 líneas. Salta cualquier texto basura hasta encontrar una línea con texto válido (ej. \"Pieles y cueros\").\n",
    "\n",
    "        Si encuentra otro Capítulo o Sección antes de encontrar una descripción, se detiene para evitar errores cruzados.\n",
    "\n",
    "    Limpieza de Texto (limpiar_descripcion):\n",
    "\n",
    "        Una vez hallada la descripción, se eliminan los puntos suspensivos del índice (....) y los números de página finales (390), dejando solo el texto puro (\"Pieles y cueros\").\n",
    "\n",
    "    Mapeo Jerárquico:\n",
    "\n",
    "        Se guardan los resultados en diccionarios (dict_capitulos, dict_secciones).\n",
    "\n",
    "        Se crea un mapa de relación (mapa_cap_sec) que recuerda qué Sección estaba activa cuando se leyó un Capítulo. Esto permite saber después que el Capítulo 01 pertenece a la Sección I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1acae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FASE 1: Generando catálogos (Escanear primeras 25 págs) ---\n",
      "Catálogos listos: 98 Capítulos detectados.\n",
      "\n",
      "--- FASE 2: Extracción de tablas de datos ---\n",
      "Procesando página 1/1315...\n",
      "Procesando página 51/1315...\n",
      "Procesando página 101/1315...\n",
      "Procesando página 151/1315...\n",
      "Procesando página 201/1315...\n",
      "Procesando página 251/1315...\n",
      "Procesando página 301/1315...\n",
      "Procesando página 351/1315...\n",
      "Procesando página 401/1315...\n",
      "Procesando página 451/1315...\n",
      "Procesando página 501/1315...\n",
      "Procesando página 551/1315...\n",
      "Procesando página 601/1315...\n",
      "Procesando página 651/1315...\n",
      "Procesando página 701/1315...\n",
      "Procesando página 751/1315...\n",
      "Procesando página 801/1315...\n",
      "Procesando página 851/1315...\n",
      "Procesando página 901/1315...\n",
      "Procesando página 951/1315...\n",
      "Procesando página 1001/1315...\n",
      "Procesando página 1051/1315...\n",
      "Procesando página 1101/1315...\n",
      "Procesando página 1151/1315...\n",
      "Procesando página 1201/1315...\n",
      "¡OBJETIVO ENCONTRADO! Código 9807.00.01 detectado en pág 1226.\n",
      "\n",
      "--- FASE 3: Procesamiento y Exportación ---\n",
      "Aplicando relleno de códigos...\n",
      "Extrayendo descripciones jerárquicas...\n",
      "Desglosando dígitos...\n",
      "Formateando textos (Mayúsculas y Puntos)...\n",
      "Generando concatenación limpia...\n",
      "Generando archivo Excel: LIGIE_Maestra_Unificada.xlsx ...\n",
      "¡PROCESO FINALIZADO CON ÉXITO!\n"
     ]
    }
   ],
   "source": [
    "def generar_catalogos_final(pdf_path, paginas_a_escanear=25):\n",
    "    print(f\"--- FASE 1: Generando catálogos (Escanear primeras {paginas_a_escanear} págs) ---\")\n",
    "    \n",
    "    dict_capitulos = {}\n",
    "    dict_secciones = {}\n",
    "    mapa_cap_sec = {} \n",
    "    \n",
    "    # Regex para capturar el número romano o arábigo\n",
    "    regex_seccion = re.compile(r\"^(?:Sección|SECCIÓN|Seccion)\\s+([IVXLCDM]+)\", re.IGNORECASE) \n",
    "    regex_capitulo = re.compile(r\"^(?:Capítulo|CAPÍTULO|Capitulo)\\s+(\\d+)\", re.IGNORECASE)\n",
    "    \n",
    "    # Textos \"basura\" que interrumpen la lectura\n",
    "    TEXTOS_BASURA = [\n",
    "        \"Calle Pachuca\", \"www.gob.mx\", \"Tel:\", \"(55) 5729\", \n",
    "        \"Economía\", \"Secretaría de Economía\", \n",
    "        \"Dirección General\", \"Facilitación\", \"Comercial y de Comercio Exterior\",\n",
    "        \"PISTON MOLLICA\", \"Versión unificada\", \"Dudas y/o comentarios\",\n",
    "        \"nueva.ligie\", \"Hoja\", \"Página\", \"The following table\", \n",
    "        \"Índice de abreviaturas\", \"Documento referencial\", \n",
    "        \"Ley de los Impuestos\", \"7ma Enmienda\", \"Acuerdo por el que\"\n",
    "    ]\n",
    "\n",
    "    # 1. Carga masiva de líneas\n",
    "    all_lines = []\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            limit = min(paginas_a_escanear, len(pdf.pages))\n",
    "            for i in range(limit):\n",
    "                page = pdf.pages[i]\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    lines = [l.strip() for l in text.split('\\n') if l.strip()]\n",
    "                    all_lines.extend(lines)\n",
    "    except Exception as e:\n",
    "        print(f\"Error crítico leyendo PDF para catálogos: {e}\")\n",
    "        return {}, {}, {}\n",
    "\n",
    "    total_lines = len(all_lines)\n",
    "\n",
    "    # 2. Funciones de limpieza\n",
    "    def es_linea_util(txt):\n",
    "        if not txt: return False\n",
    "        txt_lower = txt.lower()\n",
    "        if any(basura.lower() in txt_lower for basura in TEXTOS_BASURA): return False\n",
    "        if re.match(r'^[\\d\\.\\s]+$', txt): return False\n",
    "        if len(txt) < 3: return False\n",
    "        return True\n",
    "\n",
    "    def limpiar_descripcion(txt):\n",
    "        txt = re.split(r'\\.{2,}', txt)[0]\n",
    "        txt = re.sub(r'\\s+\\d+$', '', txt)\n",
    "        txt = txt.lstrip('.- ').strip()\n",
    "        return txt\n",
    "\n",
    "    def buscar_descripcion_real(start_index, match_obj):\n",
    "        # A. Intentar en la misma línea\n",
    "        parte_match = match_obj.group(0)\n",
    "        resto_linea = all_lines[start_index][len(parte_match):].strip()\n",
    "        resto_linea = re.split(r'\\.{2,}', resto_linea)[0].strip()\n",
    "        \n",
    "        if len(resto_linea) > 2 and not re.match(r'^[\\d\\.]+$', resto_linea):\n",
    "            return limpiar_descripcion(resto_linea)\n",
    "        \n",
    "        # B. Buscar hacia abajo\n",
    "        for offset in range(1, 15):\n",
    "            if start_index + offset >= total_lines: break\n",
    "            next_line = all_lines[start_index + offset].strip()\n",
    "            \n",
    "            if regex_seccion.match(next_line) or regex_capitulo.match(next_line):\n",
    "                return None \n",
    "            \n",
    "            if es_linea_util(next_line):\n",
    "                return limpiar_descripcion(next_line)\n",
    "        return None\n",
    "\n",
    "    # 3. Procesamiento\n",
    "    seccion_actual_romana = \"ND\"\n",
    "\n",
    "    for idx, line in enumerate(all_lines):\n",
    "        match_sec = regex_seccion.match(line)\n",
    "        match_cap = regex_capitulo.match(line)\n",
    "\n",
    "        if match_sec:\n",
    "            num = match_sec.group(1).strip()\n",
    "            seccion_actual_romana = num\n",
    "            desc = buscar_descripcion_real(idx, match_sec)\n",
    "            if desc:\n",
    "                dict_secciones[num] = desc.upper()\n",
    "        \n",
    "        elif match_cap:\n",
    "            num_raw = match_cap.group(1).strip()\n",
    "            key = f\"{int(num_raw):02d}\"\n",
    "            mapa_cap_sec[key] = seccion_actual_romana\n",
    "            desc = buscar_descripcion_real(idx, match_cap)\n",
    "            if desc:\n",
    "                dict_capitulos[key] = desc\n",
    "            else:\n",
    "                dict_capitulos[key] = \"DESCRIPCIÓN NO ENCONTRADA\"\n",
    "\n",
    "    return dict_capitulos, dict_secciones, mapa_cap_sec\n",
    "\n",
    "# Ejecutar Fase 1\n",
    "CAPITULOS_NOMBRES, SECCIONES_NOMBRES, MAPA_CAPITULO_SECCION = generar_catalogos_final(PDF_PATH)\n",
    "print(f\"Catálogos listos: {len(CAPITULOS_NOMBRES)} Capítulos detectados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22744f90",
   "metadata": {},
   "source": [
    "### Fase 2: Extracción de Tablas\n",
    "\n",
    "Una vez que tenemos los catálogos, pasamos a extraer la información dura del resto del documento.\n",
    "\n",
    "    Detección de Área de Interés:\n",
    "\n",
    "        El script itera por cada página buscando la palabra clave \"CÓDIGO\" (el encabezado de la tabla).\n",
    "\n",
    "        Usa la coordenada vertical (bottom) de esa palabra para recortar (crop) la página. Todo lo que esté arriba de ese encabezado (logos, títulos de secretaría) es ignorado para no ensuciar la tabla.\n",
    "\n",
    "    Extracción (extract_table):\n",
    "\n",
    "        Se usa la estrategia lines. pdfplumber busca las líneas negras verticales y horizontales para reconstruir la celda de Excel.\n",
    "\n",
    "        Se genera un DataFrame temporal por cada página.\n",
    "\n",
    "    Limpieza a Nivel Fila:\n",
    "\n",
    "        Se eliminan filas que sean repeticiones de encabezados (filas que contienen palabras como \"TASA\", \"IMPUESTO\", \"ARANCEL\").\n",
    "\n",
    "        Se eliminan filas de paginación o filas vacías que no contienen códigos ni descripciones útiles.\n",
    "\n",
    "    Criterio de Parada:\n",
    "\n",
    "        En cada página, se verifica si el CODIGO_STOP está presente. Si se encuentra, se cortan los datos hasta esa fila y se detiene el bucle de lectura de páginas completamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "COLUMNAS_ESPERADAS = [\"CODIGO\", \"NICO\", \"DESCRIPCION\", \"UNIDAD\", \"IMP_IMP\", \"IMP_EXP\", \"ACOTACION\"]\n",
    "PALABRAS_PROHIBIDAS = [\"SUBP\", \"IMPUESTO\", \"EXP.\", \"IMP.\", \"TASA\", \"CUOTA\", \"TRATADO\", \"ARANCEL\"]\n",
    "stop_process_flag = False\n",
    "\n",
    "print(f\"\\n--- FASE 2: Extracción de tablas de datos ---\")\n",
    "\n",
    "try:\n",
    "    with pdfplumber.open(PDF_PATH) as pdf:\n",
    "        total = len(pdf.pages)\n",
    "        # Empezamos después del índice para acelerar (aprox pág 13), o desde 0 para seguridad\n",
    "        start_page = 0 \n",
    "        \n",
    "        for i in range(start_page, total):\n",
    "            if stop_process_flag: break\n",
    "            page = pdf.pages[i]\n",
    "\n",
    "            # Buscar encabezado de tabla\n",
    "            busqueda = page.search(\"CÓDIGO\")\n",
    "            crop_y = 0\n",
    "            found_header = False\n",
    "\n",
    "            if busqueda:\n",
    "                crop_y = busqueda[0][\"bottom\"] + 2\n",
    "                found_header = True\n",
    "\n",
    "            if found_header:\n",
    "                try:\n",
    "                    cropped_page = page.crop((0, crop_y, page.width, page.height))\n",
    "                    table_settings = {\"vertical_strategy\": \"lines\", \"horizontal_strategy\": \"lines\", \"snap_tolerance\": 4}\n",
    "                    table = cropped_page.extract_table(table_settings)\n",
    "\n",
    "                    if table:\n",
    "                        df = pd.DataFrame(table)\n",
    "                        df = df.dropna(how='all')\n",
    "\n",
    "                        # Limpiar filas basura repetitivas dentro de la tabla\n",
    "                        def es_fila_basura(row):\n",
    "                            texto_fila = \" \".join([str(x) for x in row if x is not None]).upper()\n",
    "                            return any(palabra in texto_fila for palabra in PALABRAS_PROHIBIDAS)\n",
    "\n",
    "                        while not df.empty and es_fila_basura(df.iloc[0]):\n",
    "                            df = df.iloc[1:]\n",
    "                            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                        if df.shape[1] >= 7:\n",
    "                            conteos = df.count()\n",
    "                            indices_top = conteos.nlargest(7).index.sort_values()\n",
    "                            df = df[indices_top]\n",
    "                            df.columns = COLUMNAS_ESPERADAS\n",
    "\n",
    "                            mask_basura = (df['CODIGO'].isna() | (df['CODIGO'] == '')) & \\\n",
    "                                          (df['DESCRIPCION'].str.contains(\"Página\", case=False, na=False))\n",
    "                            df = df[~mask_basura]\n",
    "\n",
    "                            codigos_str = df['CODIGO'].astype(str).str.strip()\n",
    "                            if CODIGO_STOP in codigos_str.values:\n",
    "                                print(f\"¡OBJETIVO ENCONTRADO! Código {CODIGO_STOP} detectado en pág {i+1}.\")\n",
    "                                idx_stop = df[codigos_str == CODIGO_STOP].index[0]\n",
    "                                df = df.iloc[:idx_stop + 1]\n",
    "                                stop_process_flag = True\n",
    "\n",
    "                            all_data.append(df)\n",
    "                except Exception: pass\n",
    "\n",
    "            if i % 50 == 0: print(f\"Procesando página {i+1}/{total}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error abriendo PDF en Fase 2: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8b5cf",
   "metadata": {},
   "source": [
    "### Fase 3: Procesamiento y Lógica Jerárquica\n",
    "\n",
    "Aquí ocurre la transformación de datos crudos a información estructurada.\n",
    "\n",
    "    Unificación y Limpieza Inicial:\n",
    "\n",
    "        Se concatenan todas las tablas de todas las páginas en un gran DataFrame maestro.\n",
    "\n",
    "        Se eliminan saltos de línea (\\n) dentro de las celdas para que el texto sea continuo.\n",
    "\n",
    "    Lógica de Relleno (Backfill):\n",
    "\n",
    "        En la LIGIE, a veces aparece la descripción de una Partida (ej. \"Caballos\") y en la siguiente fila aparece el código desglosado (\"0101.21.01\"). La fila de \"Caballos\" tiene el código vacío.\n",
    "\n",
    "        Acción: El script usa bfill() (Back Fill). Si una celda de código está vacía, mira hacia abajo, toma el código de la siguiente fila (ej. \"0101.21.01\") y recorta el último par de dígitos. Así, asigna retroactivamente el código padre a la descripción huérfana.\n",
    "\n",
    "    Auto-Aprendizaje de Diccionarios:\n",
    "\n",
    "        El script barre todo el DataFrame buscando códigos de longitudes específicas para aprender qué es qué:\n",
    "\n",
    "            4 dígitos = Partida.\n",
    "\n",
    "            5 dígitos = Desdoblamiento (Nivel intermedio).\n",
    "\n",
    "            6 dígitos = Subpartida.\n",
    "\n",
    "        Guarda estas descripciones en nuevos diccionarios para usarlos más tarde en la concatenación.\n",
    "\n",
    "    Filtrado de \"Hojas\" (Nivel Fracción):\n",
    "\n",
    "        Se filtra el DataFrame para quedarse únicamente con los registros finales: aquellos que tienen 8 dígitos + NICO y una Tasa de Impuesto definida. Esto elimina los encabezados intermedios (que ya guardamos en diccionarios) y deja solo los productos importables.\n",
    "\n",
    "    Desglose y Mapeo (Enriquecimiento):\n",
    "\n",
    "        Desglose: Se separa el código \"01020304\" en columnas individuales: Show_Capitulo (\"01\"), Show_Partida (\"02\"), Show_Desdoblamiento (\"0\"), Show_Subpartida (\"3\"), etc.\n",
    "\n",
    "        Mapeo de Texto: Usando los diccionarios creados en la Fase 1 y Fase 3, se crea una columna de texto para cada nivel.\n",
    "\n",
    "            Ejemplo: La columna Txt_Capitulo busca \"01\" en el diccionario y devuelve \"Animales Vivos.\".\n",
    "\n",
    "        Homogenización: Se aplica formato de texto: Primera letra mayúscula (Capitalize) y se asegura que todos terminen en punto final ..\n",
    "\n",
    "    Concatenación de Texto:\n",
    "\n",
    "        Se crea la columna Texto_Concatenado. El script toma todos los textos jerárquicos (Sección, Capítulo, Partida, Desdoblamiento, Subpartida, Fracción).\n",
    "\n",
    "        Une estos textos usando un espacio simple. Al tener puntuación asegurada en el paso anterior, el resultado es una oración fluida y legible.\n",
    "\n",
    "### Fase 4: Exportación (Excel)\n",
    "\n",
    "La etapa final es verter los datos procesados en un archivo .xlsx ordenado y formateado.\n",
    "\n",
    "    Creación de Paneles (Sub-tablas):\n",
    "\n",
    "        Se crean 4 DataFrames derivados con distintas columnas según la necesidad:\n",
    "\n",
    "            LIGIE: Datos crudos procesados.\n",
    "\n",
    "            Reducido: Enfoque numérico (Códigos desglosados y tasas).\n",
    "\n",
    "            Textual: Enfoque descriptivo (Nombres de niveles y tasas).\n",
    "\n",
    "            Extendido: La matriz completa (Números + Nombres).\n",
    "\n",
    "            Concatenado: Código completo + Descripción unificada.\n",
    "\n",
    "    Motor de Excel (xlsxwriter):\n",
    "\n",
    "        Se inicia el motor de escritura de Excel.\n",
    "\n",
    "    Estilizado Inteligente:\n",
    "\n",
    "        Se definen formatos: Encabezados en azul y negrita, bordes en todas las celdas.\n",
    "\n",
    "        Wrap Text (Ajuste de texto): Se aplica condicionalmente. Si la columna contiene descripciones largas o la columna \"ACOTACION\", se activa el ajuste de línea para que el texto no se desborde ni se oculte.\n",
    "\n",
    "    Ajuste de Anchos:\n",
    "\n",
    "        Columnas de códigos (ej. \"Capítulo\"): Ancho 8 (angosto).\n",
    "\n",
    "        Columnas de texto (ej. \"Descripción\"): Ancho 50 (amplio).\n",
    "\n",
    "        Resto de columnas: Ancho 12 (estándar).\n",
    "\n",
    "    Escritura: Se guardan las 5 pestañas y se cierra el archivo, finalizando el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_data:\n",
    "    print(\"\\n--- FASE 3: Procesamiento y Exportación ---\")\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    final_df = final_df.replace(r'\\n', ' ', regex=True)\n",
    "\n",
    "    # 1. Relleno Jerárquico\n",
    "    print(\"Aplicando relleno de códigos...\")\n",
    "    final_df['NICO'] = final_df['NICO'].fillna('').astype(str).str.strip().replace(['--', '-'], '')\n",
    "    final_df['CODIGO'] = final_df['CODIGO'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    \n",
    "    siguientes_codigos = final_df['CODIGO'].bfill()\n",
    "    cond_codigo_vacio = final_df['CODIGO'].isna()\n",
    "    cond_nico_vacio = final_df['NICO'] == ''\n",
    "    mascara = cond_codigo_vacio & cond_nico_vacio\n",
    "    \n",
    "    if not siguientes_codigos[mascara].empty:\n",
    "        final_df.loc[mascara, 'CODIGO'] = siguientes_codigos[mascara].astype(str).str[:-1]\n",
    "\n",
    "    final_df = final_df.fillna('')\n",
    "\n",
    "    # 2. Generación de Diccionarios (Partida, Desdoblamiento, Subpartida)\n",
    "    print(\"Extrayendo descripciones jerárquicas...\")\n",
    "    panel_base = final_df.copy()\n",
    "    panel_base['CODIGO_LIMPIO'] = panel_base['CODIGO'].astype(str).str.replace('.', '', regex=False).str.strip()\n",
    "\n",
    "    dict_partidas = {}       # 4 dígitos\n",
    "    dict_desdoblamiento = {} # 5 dígitos\n",
    "    dict_subpartidas = {}    # 6 dígitos\n",
    "\n",
    "    for row in panel_base.itertuples():\n",
    "        code = getattr(row, 'CODIGO_LIMPIO', '')\n",
    "        desc = getattr(row, 'DESCRIPCION', '')\n",
    "        \n",
    "        if len(code) == 4:\n",
    "            dict_partidas[code] = desc\n",
    "        elif len(code) == 5:\n",
    "            dict_desdoblamiento[code] = desc\n",
    "        elif len(code) == 6:\n",
    "            dict_subpartidas[code] = desc\n",
    "\n",
    "    # 3. Filtrado Final (Solo filas de producto final)\n",
    "    panel_df = panel_base[\n",
    "        (panel_base['CODIGO_LIMPIO'].str.len() == 8) &\n",
    "        (panel_base['IMP_IMP'].str.strip() != '')\n",
    "    ].copy()\n",
    "    \n",
    "    panel_df = panel_df.drop_duplicates(subset=['CODIGO', 'NICO'], keep='first')\n",
    "\n",
    "    # 4. Desglose de Dígitos (Columnas numéricas \"Show_\")\n",
    "    print(\"Desglosando dígitos...\")\n",
    "    code_full = panel_df['CODIGO_LIMPIO']\n",
    "    \n",
    "    panel_df['Show_Capitulo']       = code_full.str[:2]\n",
    "    panel_df['Show_Partida']        = code_full.str[2:4]\n",
    "    panel_df['Show_Desdoblamiento'] = code_full.str[4:5]\n",
    "    panel_df['Show_Subpartida']     = code_full.str[5:6]\n",
    "    panel_df['Show_Fraccion']       = code_full.str[6:8]\n",
    "\n",
    "    # 5. Mapeo de Textos\n",
    "    def get_seccion_romana(cap_code):\n",
    "        return MAPA_CAPITULO_SECCION.get(cap_code, \"ND\")\n",
    "\n",
    "    panel_df['Txt_Seccion_Romana'] = code_full.str[:2].apply(get_seccion_romana)\n",
    "    \n",
    "    panel_df['Txt_Seccion_Nombre'] = panel_df['Txt_Seccion_Romana'].map(SECCIONES_NOMBRES)\n",
    "    panel_df['Txt_Capitulo']       = code_full.str[:2].map(CAPITULOS_NOMBRES)\n",
    "    panel_df['Txt_Partida']        = code_full.str[:4].map(dict_partidas)\n",
    "    panel_df['Txt_Desdoblamiento'] = code_full.str[:5].map(dict_desdoblamiento)\n",
    "    panel_df['Txt_Subpartida']     = code_full.str[:6].map(dict_subpartidas)\n",
    "\n",
    "    # 6. Homogenización de Formatos de Texto\n",
    "    print(\"Formateando textos (Mayúsculas y Puntos)...\")\n",
    "    \n",
    "    # Sección: Capitalize + Punto\n",
    "    panel_df['Txt_Seccion_Nombre'] = panel_df['Txt_Seccion_Nombre'].fillna('').astype(str).str.lower().str.capitalize()\n",
    "    panel_df['Txt_Seccion_Nombre'] = panel_df['Txt_Seccion_Nombre'].str.rstrip('.') + '.'\n",
    "    \n",
    "    # Capítulo: Asegurar punto final\n",
    "    panel_df['Txt_Capitulo'] = panel_df['Txt_Capitulo'].fillna('').astype(str).str.rstrip('.') + '.'\n",
    "\n",
    "    panel_df['Codigo_Completo'] = panel_df['CODIGO']\n",
    "\n",
    "    # 7. Concatenación (Sin PIPES, solo espacio)\n",
    "    print(\"Generando concatenación limpia...\")\n",
    "    \n",
    "    def concatenar_descripciones(row):\n",
    "        items = [\n",
    "            row['Txt_Seccion_Nombre'],\n",
    "            row['Txt_Capitulo'],\n",
    "            row['Txt_Partida'],\n",
    "            row['Txt_Desdoblamiento'],\n",
    "            row['Txt_Subpartida'],\n",
    "            row['DESCRIPCION']\n",
    "        ]\n",
    "        # Unir con espacio simple. Filtra vacíos y 'nan'.\n",
    "        return \" \".join([str(x).strip() for x in items if str(x).strip() != '' and str(x).strip() != 'nan'])\n",
    "\n",
    "    panel_df['Texto_Concatenado'] = panel_df.apply(concatenar_descripciones, axis=1)\n",
    "\n",
    "    # --- DEFINICIÓN DE ESTRUCTURAS DE SALIDA ---\n",
    "\n",
    "    # Panel Reducido\n",
    "    cols_reducido = [\n",
    "        'Codigo_Completo', 'Txt_Seccion_Romana', \n",
    "        'Show_Capitulo', 'Show_Partida', 'Show_Desdoblamiento', 'Show_Subpartida', 'Show_Fraccion', \n",
    "        'UNIDAD', 'IMP_IMP', 'IMP_EXP'\n",
    "    ]\n",
    "    df_reducido = panel_df[cols_reducido].copy()\n",
    "    df_reducido.columns = [\n",
    "        'Código Completo', 'Sección', \n",
    "        'Capítulo', 'Partida', 'Desdoblamiento', 'Subpartida', 'Fracción', \n",
    "        'Unidad', 'Imp. Imp.', 'Imp. Exp.'\n",
    "    ]\n",
    "\n",
    "    # Panel Textual\n",
    "    cols_textual = [\n",
    "        'Codigo_Completo', \n",
    "        'Txt_Seccion_Nombre', 'Txt_Capitulo', 'Txt_Partida', \n",
    "        'Txt_Desdoblamiento', 'Txt_Subpartida', \n",
    "        'DESCRIPCION', \n",
    "        'UNIDAD', 'IMP_IMP', 'IMP_EXP'\n",
    "    ]\n",
    "    df_textual = panel_df[cols_textual].copy()\n",
    "    df_textual.columns = [\n",
    "        'Código Completo', \n",
    "        'Nombre Sección', 'Nombre Capítulo', 'Nombre Partida', \n",
    "        'Nombre Desdoblamiento', 'Nombre Subpartida', \n",
    "        'Descripción Fracción', \n",
    "        'Unidad', 'Imp. Imp.', 'Imp. Exp.'\n",
    "    ]\n",
    "\n",
    "    # Panel Extendido\n",
    "    cols_extendido = [\n",
    "        'Codigo_Completo', \n",
    "        'Txt_Seccion_Romana', 'Txt_Seccion_Nombre',\n",
    "        'Show_Capitulo', 'Txt_Capitulo',\n",
    "        'Show_Partida', 'Txt_Partida',\n",
    "        'Show_Desdoblamiento', 'Txt_Desdoblamiento', \n",
    "        'Show_Subpartida', 'Txt_Subpartida',\n",
    "        'Show_Fraccion', \n",
    "        'DESCRIPCION',   \n",
    "        'UNIDAD', 'IMP_IMP', 'IMP_EXP'\n",
    "    ]\n",
    "    df_extendido = panel_df[cols_extendido].copy()\n",
    "    df_extendido.columns = [\n",
    "        'Código Completo', \n",
    "        'Sección', 'Nombre Sección', \n",
    "        'Capítulo', 'Nombre Capítulo',\n",
    "        'Partida', 'Nombre Partida',\n",
    "        'Desdob.', 'Nombre Desdoblamiento',\n",
    "        'Subpartida', 'Nombre Subpartida',\n",
    "        'Fracción', \n",
    "        'Descripción Fracción',\n",
    "        'Unidad', 'Imp. Imp.', 'Imp. Exp.'\n",
    "    ]\n",
    "\n",
    "    # Panel Concatenado\n",
    "    cols_concat = ['Codigo_Completo', 'Texto_Concatenado', 'UNIDAD', 'IMP_IMP', 'IMP_EXP']\n",
    "    df_concatenado = panel_df[cols_concat].copy()\n",
    "    df_concatenado.columns = ['Código Completo', 'Descripción Completa Concatenada', 'Unidad', 'Imp. Imp.', 'Imp. Exp.']\n",
    "\n",
    "    # --- EXPORTACIÓN A EXCEL ---\n",
    "    nombre_salida = \"LIGIE_Maestra_Unificada.xlsx\"\n",
    "    print(f\"Generando archivo Excel: {nombre_salida} ...\")\n",
    "\n",
    "    writer = pd.ExcelWriter(nombre_salida, engine='xlsxwriter')\n",
    "    workbook = writer.book\n",
    "\n",
    "    # Formatos\n",
    "    fmt_header = workbook.add_format({'bold': True, 'border': 1, 'bg_color': '#D9E1F2', 'valign': 'top', 'align': 'center', 'font_name': 'Arial', 'font_size': 10})\n",
    "    fmt_normal = workbook.add_format({'border': 1, 'valign': 'top', 'font_name': 'Arial', 'font_size': 9})\n",
    "    fmt_wrap = workbook.add_format({'border': 1, 'valign': 'top', 'text_wrap': True, 'font_name': 'Arial', 'font_size': 9})\n",
    "\n",
    "    def escribir_hoja(dataframe, nombre_hoja):\n",
    "        worksheet = workbook.add_worksheet(nombre_hoja)\n",
    "        writer.sheets[nombre_hoja] = worksheet\n",
    "        \n",
    "        headers = dataframe.columns.tolist()\n",
    "        for col_idx, header in enumerate(headers):\n",
    "            worksheet.write(0, col_idx, header, fmt_header)\n",
    "            \n",
    "        for row_idx, row in enumerate(dataframe.itertuples(index=False), start=1):\n",
    "            for col_idx, value in enumerate(row):\n",
    "                header_name = headers[col_idx]\n",
    "                \n",
    "                # Columnas con Wrap Text: Descripciones, Nombres, Acotación y Concatenada\n",
    "                columnas_largas = [\"Nombre\", \"DESCRIPCION\", \"Descripción\", \"ACOTACION\", \"Concatenada\"]\n",
    "                es_texto_largo = any(x in header_name for x in columnas_largas)\n",
    "                \n",
    "                formato = fmt_wrap if es_texto_largo else fmt_normal\n",
    "                if pd.isna(value): value = \"\"\n",
    "                worksheet.write(row_idx, col_idx, value, formato)\n",
    "        \n",
    "        # Ajuste inteligente de anchos\n",
    "        for idx, col_name in enumerate(headers):\n",
    "            # Columnas de códigos cortos\n",
    "            if col_name in ['Capítulo', 'Partida', 'Desdob.', 'Desdoblamiento', 'Subpartida', 'Fracción', 'Sección']:\n",
    "                 worksheet.set_column(idx, idx, 8) \n",
    "            # Columnas de texto largo\n",
    "            elif any(x in col_name for x in [\"Nombre\", \"DESCRIPCION\", \"Descripción\", \"ACOTACION\", \"Concatenada\"]):\n",
    "                worksheet.set_column(idx, idx, 50) \n",
    "            # Resto (Unidad, Tasas, Código Completo)\n",
    "            else:\n",
    "                worksheet.set_column(idx, idx, 12)\n",
    "\n",
    "    # Escritura de Hojas\n",
    "    escribir_hoja(final_df, \"LIGIE\") \n",
    "    escribir_hoja(df_reducido, \"Panel Reducido\")\n",
    "    escribir_hoja(df_textual, \"Panel Textual\")\n",
    "    escribir_hoja(df_extendido, \"Panel Extendido\")\n",
    "    escribir_hoja(df_concatenado, \"Concatenado\")\n",
    "\n",
    "    writer.close()\n",
    "    print(\"¡PROCESO FINALIZADO CON ÉXITO!\")\n",
    "\n",
    "else:\n",
    "    print(\"No se encontraron datos para exportar. Verifica el archivo PDF.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
