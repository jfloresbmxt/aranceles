{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6d759b",
   "metadata": {},
   "source": [
    "# Limpieza LIGIE\n",
    "## Fases de Tratado\n",
    "### Fase 0: Configuración General\n",
    "\n",
    "Antes de iniciar cualquier lógica, es fundamental preparar el entorno de ejecución instalando las dependencias necesarias y comprendiendo las herramientas que manipularán el archivo PDF y las estructuras de datos.\n",
    "\n",
    "Instalación de dependencias: Para asegurar que el script funcione correctamente, se deben instalar las librerías externas que no vienen incluidas por defecto en Python. Ejecuta el siguiente comando en tu terminal o en una celda de tu entorno de desarrollo:\n",
    "\n",
    "- pip install pdfplumber pandas numpy xlsxwriter\n",
    "\n",
    "Librerías:\n",
    "\n",
    "- pdfplumber: Es el motor principal de extracción. Se elige sobre otras opciones (como PyPDF2) porque permite estrategias visuales (detección de líneas de tablas) y lectura de texto posicional precisa.\n",
    "\n",
    "- pandas (pd): Utilizada para crear los DataFrames. Es vital para manipular filas, columnas, rellenar datos faltantes (NaN) y transformar texto masivamente.\n",
    "\n",
    "- numpy (np): Se usa auxiliarmente para definir valores nulos (np.nan) que pandas pueda reconocer y tratar.\n",
    "\n",
    "- re: Librería de Expresiones Regulares. Es el \"cerebro\" que identifica patrones de texto complejos (ej. detectar si una línea empieza con \"Sección IV\" o \"Capítulo 85\").\n",
    "\n",
    "- os: Utilidad de sistema operativo para manejo de rutas de archivos.\n",
    "\n",
    "Variables Globales:\n",
    "\n",
    "- os.chdir(''): Define el directorio de trabajo.\n",
    "\n",
    "- PDF_PATH: Define la ruta del archivo origen.\n",
    "\n",
    "- CODIGO_STOP: El script dejará de leer el PDF cuando encuentre este código específico (9807.00.01), optimizando tiempo al evitar leer anexos irrelevantes al final del documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0947e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pdfplumber pandas numpy xlsxwriter\n",
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "PDF_PATH = \"../data/raw/LIGIE-UNIFICADA-LIGIE_20250728-20250728.pdf\"\n",
    "CODIGO_STOP = \"9807.00.01\"\n",
    "\n",
    "REGEX_SECCION = re.compile(r\"^(?:Sección|SECCIÓN|Seccion)\\s+([IVXLCDM]+)\", re.IGNORECASE) \n",
    "REGEX_CAPITULO = re.compile(r\"^(?:Capítulo|CAPÍTULO|Capitulo)\\s+(\\d+)\", re.IGNORECASE)\n",
    "\n",
    "TEXTOS_BASURA = [\n",
    "    \"Calle Pachuca\", \"www.gob.mx\", \"Tel:\", \"(55) 5729\", \n",
    "    \"Economía\", \"Secretaría de Economía\", \n",
    "    \"Dirección General\", \"Facilitación\", \"Comercial y de Comercio Exterior\",\n",
    "    \"PISTON MOLLICA\", \"Versión unificada\", \"Dudas y/o comentarios\",\n",
    "    \"nueva.ligie\", \"Hoja\", \"Página\", \"The following table\", \n",
    "    \"Índice de abreviaturas\", \"Documento referencial\", \n",
    "    \"Ley de los Impuestos\", \"7ma Enmienda\", \"Acuerdo por el que\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_markdown_definitions",
   "metadata": {},
   "source": [
    "### Fase 0.5: Definición de Funciones\n",
    "\n",
    "En esta sección centralizamos toda la lógica del script. Esto permite mantener las fases posteriores limpias, conteniendo únicamente la ejecución del código. Las funciones se clasifican según su naturaleza:\n",
    "\n",
    "**1. Funciones Auxiliares (`_nombre`)**\n",
    "Herramientas de soporte para tareas repetitivas de limpieza y validación.\n",
    "\n",
    "* **`_es_linea_util`**: Filtro de calidad. Recibe una línea de texto y decide si es información válida o \"basura\" (números de página, direcciones, encabezados repetitivos).\n",
    "* **`_limpiar_descripcion`**: Formateador de texto. Elimina los caracteres de relleno del índice (como `....`) y números de página para dejar limpia la descripción de un Capítulo.\n",
    "* **`_es_fila_basura`**: Filtro de tablas. Detecta si una fila extraída de una tabla es en realidad un encabezado repetido (ej. contiene \"TASA\" o \"IMPUESTO\").\n",
    "* **`_get_seccion_romana`**: Buscador simple. Dado un código de Capítulo (ej. \"01\"), busca en el mapa generado a qué Sección Romana pertenece (ej. \"I\").\n",
    "* **`_concatenar_descripciones`**: Constructor de texto. Toma las partes jerárquicas (Sección, Capítulo, Partida, Fracción) y las une en una sola oración fluida.\n",
    "\n",
    "**2. Funciones Críticas (`__nombre__`)**\n",
    "Lógica estructural compleja o delicada que no debe modificarse a la ligera.\n",
    "\n",
    "* **`__buscar_descripcion_real__`**: Motor de búsqueda *Lookahead*. Es el corazón de la lectura del índice. Si encuentra un título (ej. \"Capítulo 85\") sin descripción, escanea las líneas siguientes de manera inteligente hasta encontrar el texto correcto, saltándose la basura.\n",
    "* **`__escribir_hoja__`**: Motor de exportación Excel. Controla la librería `xlsxwriter` para crear pestañas, aplicar negritas, bordes y, lo más importante, calcular el ajuste de texto (Wrap Text) y anchos de columna para que el reporte sea legible.\n",
    "\n",
    "**3. Funciones Principales (`nombre`)**\n",
    "Ejecutan procesos completos.\n",
    "\n",
    "* **`generar_catalogos_final`**: Coordina la lectura masiva de las primeras páginas del PDF, invoca a las funciones regex y de búsqueda (`__buscar_descripcion_real__`) y retorna los diccionarios maestros de Secciones y Capítulos listos para usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "new_code_definitions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUNCIONES AUXILIARES ---\n",
    "\n",
    "def _es_linea_util(txt):\n",
    "    if not txt: return False\n",
    "    txt_lower = txt.lower()\n",
    "    if any(basura.lower() in txt_lower for basura in TEXTOS_BASURA): return False\n",
    "    if re.match(r'^[\\d\\.\\s]+$', txt): return False\n",
    "    if len(txt) < 3: return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def _limpiar_descripcion(txt):\n",
    "    txt = re.split(r'\\.{2,}', txt)[0]\n",
    "    txt = re.sub(r'\\s+\\d+$', '', txt)\n",
    "    txt = txt.lstrip('.- ').strip()\n",
    "    return txt\n",
    "\n",
    "\n",
    "def _es_fila_basura(row, palabras_prohibidas):\n",
    "    texto_fila = \" \".join([str(x) for x in row if x is not None]).upper()\n",
    "    return any(palabra in texto_fila for palabra in palabras_prohibidas)\n",
    "\n",
    "\n",
    "def _get_seccion_romana(cap_code, mapa):\n",
    "    return mapa.get(cap_code, \"ND\")\n",
    "\n",
    "\n",
    "def _concatenar_descripciones(row):\n",
    "    items = [\n",
    "        row.get('Txt_Seccion_Nombre', ''),\n",
    "        row.get('Txt_Capitulo', ''),\n",
    "        row.get('Txt_Partida', ''),\n",
    "        row.get('Txt_Desdoblamiento', ''),\n",
    "        row.get('Txt_Subpartida', ''),\n",
    "        row.get('DESCRIPCION', '')\n",
    "    ]\n",
    "    return \" \".join([str(x).strip() for x in items if str(x).strip() != '' and str(x).strip() != 'nan'])\n",
    "\n",
    "\n",
    "# --- FUNCIONES CRÍTICAS ---\n",
    "\n",
    "def __buscar_descripcion_real__(start_index, match_obj, all_lines):\n",
    "    total_lines = len(all_lines)\n",
    "    \n",
    "    # A. Intentar en la misma línea\n",
    "    parte_match = match_obj.group(0)\n",
    "    resto_linea = all_lines[start_index][len(parte_match):].strip()\n",
    "    resto_linea = re.split(r'\\.{2,}', resto_linea)[0].strip()\n",
    "    \n",
    "    if len(resto_linea) > 2 and not re.match(r'^[\\d\\.]+$', resto_linea):\n",
    "        return _limpiar_descripcion(resto_linea)\n",
    "    \n",
    "    # B. Buscar hacia abajo (Lookahead)\n",
    "    for offset in range(1, 15):\n",
    "        if start_index + offset >= total_lines: break\n",
    "        next_line = all_lines[start_index + offset].strip()\n",
    "        \n",
    "        if REGEX_SECCION.match(next_line) or REGEX_CAPITULO.match(next_line):\n",
    "            return None \n",
    "        \n",
    "        if _es_linea_util(next_line):\n",
    "            return _limpiar_descripcion(next_line)\n",
    "    return None\n",
    "\n",
    "\n",
    "def __escribir_hoja__(dataframe, nombre_hoja, writer, workbook):\n",
    "    # Definición de formatos\n",
    "    fmt_header = workbook.add_format({'bold': True, 'border': 1, 'bg_color': '#D9E1F2', 'valign': 'top', 'align': 'center', 'font_name': 'Arial', 'font_size': 10})\n",
    "    fmt_normal = workbook.add_format({'border': 1, 'valign': 'top', 'font_name': 'Arial', 'font_size': 9})\n",
    "    fmt_wrap = workbook.add_format({'border': 1, 'valign': 'top', 'text_wrap': True, 'font_name': 'Arial', 'font_size': 9})\n",
    "\n",
    "    worksheet = workbook.add_worksheet(nombre_hoja)\n",
    "    writer.sheets[nombre_hoja] = worksheet\n",
    "    \n",
    "    headers = dataframe.columns.tolist()\n",
    "    for col_idx, header in enumerate(headers):\n",
    "        worksheet.write(0, col_idx, header, fmt_header)\n",
    "        \n",
    "    for row_idx, row in enumerate(dataframe.itertuples(index=False), start=1):\n",
    "        for col_idx, value in enumerate(row):\n",
    "            header_name = headers[col_idx]\n",
    "            columnas_largas = [\"Nombre\", \"DESCRIPCION\", \"Descripción\", \"ACOTACION\", \"Concatenada\"]\n",
    "            es_texto_largo = any(x in header_name for x in columnas_largas)\n",
    "            formato = fmt_wrap if es_texto_largo else fmt_normal\n",
    "            if pd.isna(value): value = \"\"\n",
    "            worksheet.write(row_idx, col_idx, value, formato)\n",
    "    \n",
    "    # Ajuste de anchos\n",
    "    for idx, col_name in enumerate(headers):\n",
    "        if col_name in ['Capítulo', 'Partida', 'Desdob.', 'Desdoblamiento', 'Subpartida', 'Fracción', 'Sección']:\n",
    "             worksheet.set_column(idx, idx, 8) \n",
    "        elif any(x in col_name for x in [\"Nombre\", \"DESCRIPCION\", \"Descripción\", \"ACOTACION\", \"Concatenada\"]):\n",
    "            worksheet.set_column(idx, idx, 50) \n",
    "        else:\n",
    "            worksheet.set_column(idx, idx, 12)\n",
    "\n",
    "\n",
    "# --- FUNCIONES PRINCIPALES ---\n",
    "\n",
    "def generar_catalogos_final(pdf_path, paginas_a_escanear=25):\n",
    "    print(f\"--- FASE 1: Generando catálogos (Escanear primeras {paginas_a_escanear} págs) ---\")\n",
    "    \n",
    "    dict_capitulos = {}\n",
    "    dict_secciones = {}\n",
    "    mapa_cap_sec = {} \n",
    "    \n",
    "    # 1. Carga masiva de líneas\n",
    "    all_lines = []\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            limit = min(paginas_a_escanear, len(pdf.pages))\n",
    "            for i in range(limit):\n",
    "                page = pdf.pages[i]\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    lines = [l.strip() for l in text.split('\\n') if l.strip()]\n",
    "                    all_lines.extend(lines)\n",
    "    except Exception as e:\n",
    "        print(f\"Error crítico leyendo PDF para catálogos: {e}\")\n",
    "        return {}, {}, {}\n",
    "\n",
    "    # 2. Procesamiento usando funciones externas\n",
    "    seccion_actual_romana = \"ND\"\n",
    "\n",
    "    for idx, line in enumerate(all_lines):\n",
    "        match_sec = REGEX_SECCION.match(line)\n",
    "        match_cap = REGEX_CAPITULO.match(line)\n",
    "\n",
    "        if match_sec:\n",
    "            num = match_sec.group(1).strip()\n",
    "            seccion_actual_romana = num\n",
    "            # Llamada a función crítica\n",
    "            desc = __buscar_descripcion_real__(idx, match_sec, all_lines)\n",
    "            if desc:\n",
    "                dict_secciones[num] = desc.upper()\n",
    "        \n",
    "        elif match_cap:\n",
    "            num_raw = match_cap.group(1).strip()\n",
    "            key = f\"{int(num_raw):02d}\"\n",
    "            mapa_cap_sec[key] = seccion_actual_romana\n",
    "            # Llamada a función crítica\n",
    "            desc = __buscar_descripcion_real__(idx, match_cap, all_lines)\n",
    "            if desc:\n",
    "                dict_capitulos[key] = desc\n",
    "            else:\n",
    "                dict_capitulos[key] = \"DESCRIPCIÓN NO ENCONTRADA\"\n",
    "\n",
    "    return dict_capitulos, dict_secciones, mapa_cap_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f81d8",
   "metadata": {},
   "source": [
    "### Fase 1: Generación de Catálogos\n",
    "\n",
    "Esta fase ejecuta la lectura del índice inicial. Gracias a la definición previa en la Fase 0.5, el código aquí es puramente ejecutable.\n",
    "\n",
    "- Se invoca a `generar_catalogos_final` con la ruta del PDF.\n",
    "- Se reciben los diccionarios limpios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1acae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FASE 1: Generando catálogos (Escanear primeras 25 págs) ---\n",
      "Catálogos listos: 98 Capítulos detectados.\n"
     ]
    }
   ],
   "source": [
    "CAPITULOS_NOMBRES, SECCIONES_NOMBRES, MAPA_CAPITULO_SECCION = generar_catalogos_final(PDF_PATH)\n",
    "print(f\"Catálogos listos: {len(CAPITULOS_NOMBRES)} Capítulos detectados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22744f90",
   "metadata": {},
   "source": [
    "### Fase 2: Extracción de Tablas\n",
    "\n",
    "Una vez que tenemos los catálogos, pasamos a extraer la información del resto del documento.\n",
    "\n",
    "- **Estrategia**: Se iteran las páginas buscando la palabra \"CÓDIGO\" para recortar encabezados.\n",
    "- **Limpieza**: Se utiliza la función auxiliar `_es_fila_basura` para limpiar los datos crudos.\n",
    "- **Parada**: Se busca el `CODIGO_STOP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea8ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FASE 2: Extracción de tablas de datos ---\n",
      "Procesando página 1/1315...\n",
      "Procesando página 51/1315...\n",
      "Procesando página 101/1315...\n",
      "Procesando página 151/1315...\n",
      "Procesando página 201/1315...\n",
      "Procesando página 251/1315...\n",
      "Procesando página 301/1315...\n",
      "Procesando página 351/1315...\n",
      "Procesando página 401/1315...\n",
      "Procesando página 451/1315...\n",
      "Procesando página 501/1315...\n",
      "Procesando página 551/1315...\n",
      "Procesando página 601/1315...\n",
      "Procesando página 651/1315...\n",
      "Procesando página 701/1315...\n",
      "Procesando página 751/1315...\n",
      "Procesando página 801/1315...\n",
      "Procesando página 851/1315...\n",
      "Procesando página 901/1315...\n",
      "Procesando página 951/1315...\n",
      "Procesando página 1001/1315...\n",
      "Procesando página 1051/1315...\n",
      "Procesando página 1101/1315...\n",
      "Procesando página 1151/1315...\n",
      "Procesando página 1201/1315...\n",
      "¡OBJETIVO ENCONTRADO! Código 9807.00.01 detectado en pág 1226.\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "COLUMNAS_ESPERADAS = [\"CODIGO\", \"NICO\", \"DESCRIPCION\", \"UNIDAD\", \"IMP_IMP\", \"IMP_EXP\", \"ACOTACION\"]\n",
    "PALABRAS_PROHIBIDAS = [\"SUBP\", \"IMPUESTO\", \"EXP.\", \"IMP.\", \"TASA\", \"CUOTA\", \"TRATADO\", \"ARANCEL\"]\n",
    "stop_process_flag = False\n",
    "\n",
    "print(f\"\\n--- FASE 2: Extracción de tablas de datos ---\")\n",
    "\n",
    "try:\n",
    "    with pdfplumber.open(PDF_PATH) as pdf:\n",
    "        total = len(pdf.pages)\n",
    "        start_page = 0 \n",
    "        \n",
    "        for i in range(start_page, total):\n",
    "            if stop_process_flag: break\n",
    "            page = pdf.pages[i]\n",
    "\n",
    "            # Buscar encabezado de tabla\n",
    "            busqueda = page.search(\"CÓDIGO\")\n",
    "            crop_y = 0\n",
    "            found_header = False\n",
    "\n",
    "            if busqueda:\n",
    "                crop_y = busqueda[0][\"bottom\"] + 2\n",
    "                found_header = True\n",
    "\n",
    "            if found_header:\n",
    "                try:\n",
    "                    cropped_page = page.crop((0, crop_y, page.width, page.height))\n",
    "                    table_settings = {\"vertical_strategy\": \"lines\", \"horizontal_strategy\": \"lines\", \"snap_tolerance\": 4}\n",
    "                    table = cropped_page.extract_table(table_settings)\n",
    "\n",
    "                    if table:\n",
    "                        df = pd.DataFrame(table)\n",
    "                        df = df.dropna(how='all')\n",
    "\n",
    "                        # Limpiar filas basura repetitivas usando función auxiliar\n",
    "                        while not df.empty and _es_fila_basura(df.iloc[0], PALABRAS_PROHIBIDAS):\n",
    "                            df = df.iloc[1:]\n",
    "                            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                        if df.shape[1] >= 7:\n",
    "                            conteos = df.count()\n",
    "                            indices_top = conteos.nlargest(7).index.sort_values()\n",
    "                            df = df[indices_top]\n",
    "                            df.columns = COLUMNAS_ESPERADAS\n",
    "\n",
    "                            mask_basura = (df['CODIGO'].isna() | (df['CODIGO'] == '')) & \\\n",
    "                                          (df['DESCRIPCION'].str.contains(\"Página\", case=False, na=False))\n",
    "                            df = df[~mask_basura]\n",
    "\n",
    "                            codigos_str = df['CODIGO'].astype(str).str.strip()\n",
    "                            if CODIGO_STOP in codigos_str.values:\n",
    "                                print(f\"¡OBJETIVO ENCONTRADO! Código {CODIGO_STOP} detectado en pág {i+1}.\")\n",
    "                                idx_stop = df[codigos_str == CODIGO_STOP].index[0]\n",
    "                                df = df.iloc[:idx_stop + 1]\n",
    "                                stop_process_flag = True\n",
    "\n",
    "                            all_data.append(df)\n",
    "                except Exception: pass\n",
    "\n",
    "            if i % 50 == 0: print(f\"Procesando página {i+1}/{total}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error abriendo PDF en Fase 2: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8b5cf",
   "metadata": {},
   "source": [
    "### Fase 3: Procesamiento y Lógica Jerárquica\n",
    "\n",
    "Aquí ocurre la transformación de datos crudos a información estructurada.\n",
    "\n",
    "- **Relleno**: Uso de `bfill()`.\n",
    "- **Mapeo**: Uso de `_get_seccion_romana`.\n",
    "- **Concatenación**: Uso de `_concatenar_descripciones`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970ef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FASE 3: Procesamiento y Exportación ---\n",
      "Aplicando relleno de códigos...\n",
      "Extrayendo descripciones jerárquicas...\n",
      "Desglosando dígitos...\n",
      "Formateando textos (Mayúsculas y Puntos)...\n",
      "Generando concatenación limpia...\n",
      "Generando archivo Excel: LIGIE_Maestra_Unificada.xlsx ...\n",
      "¡PROCESO FINALIZADO CON ÉXITO!\n"
     ]
    }
   ],
   "source": [
    "if all_data:\n",
    "    print(\"\\n--- FASE 3: Procesamiento y Exportación ---\")\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    final_df = final_df.replace(r'\\n', ' ', regex=True)\n",
    "\n",
    "    # 1. Relleno Jerárquico\n",
    "    print(\"Aplicando relleno de códigos...\")\n",
    "    final_df['NICO'] = final_df['NICO'].fillna('').astype(str).str.strip().replace(['--', '-'], '')\n",
    "    final_df['CODIGO'] = final_df['CODIGO'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    \n",
    "    siguientes_codigos = final_df['CODIGO'].bfill()\n",
    "    cond_codigo_vacio = final_df['CODIGO'].isna()\n",
    "    cond_nico_vacio = final_df['NICO'] == ''\n",
    "    mascara = cond_codigo_vacio & cond_nico_vacio\n",
    "    \n",
    "    if not siguientes_codigos[mascara].empty:\n",
    "        final_df.loc[mascara, 'CODIGO'] = siguientes_codigos[mascara].astype(str).str[:-1]\n",
    "\n",
    "    final_df = final_df.fillna('')\n",
    "\n",
    "    # 2. Generación de Diccionarios\n",
    "    print(\"Extrayendo descripciones jerárquicas...\")\n",
    "    panel_base = final_df.copy()\n",
    "    panel_base['CODIGO_LIMPIO'] = panel_base['CODIGO'].astype(str).str.replace('.', '', regex=False).str.strip()\n",
    "\n",
    "    dict_partidas = {}       # 4 dígitos\n",
    "    dict_desdoblamiento = {} # 5 dígitos\n",
    "    dict_subpartidas = {}    # 6 dígitos\n",
    "\n",
    "    for row in panel_base.itertuples():\n",
    "        code = getattr(row, 'CODIGO_LIMPIO', '')\n",
    "        desc = getattr(row, 'DESCRIPCION', '')\n",
    "        \n",
    "        if len(code) == 4:\n",
    "            dict_partidas[code] = desc\n",
    "        elif len(code) == 5:\n",
    "            dict_desdoblamiento[code] = desc\n",
    "        elif len(code) == 6:\n",
    "            dict_subpartidas[code] = desc\n",
    "\n",
    "    # 3. Filtrado Final\n",
    "    panel_df = panel_base[\n",
    "        (panel_base['CODIGO_LIMPIO'].str.len() == 8) &\n",
    "        (panel_base['IMP_IMP'].str.strip() != '')\n",
    "    ].copy()\n",
    "    \n",
    "    panel_df = panel_df.drop_duplicates(subset=['CODIGO', 'NICO'], keep='first')\n",
    "\n",
    "    # 4. Desglose de Dígitos\n",
    "    print(\"Desglosando dígitos...\")\n",
    "    code_full = panel_df['CODIGO_LIMPIO']\n",
    "    \n",
    "    panel_df['Show_Capitulo']       = code_full.str[:2]\n",
    "    panel_df['Show_Partida']        = code_full.str[2:4]\n",
    "    panel_df['Show_Desdoblamiento'] = code_full.str[4:5]\n",
    "    panel_df['Show_Subpartida']     = code_full.str[5:6]\n",
    "    panel_df['Show_Fraccion']       = code_full.str[6:8]\n",
    "\n",
    "    # 5. Mapeo de Textos\n",
    "    panel_df['Txt_Seccion_Romana'] = code_full.str[:2].apply(lambda x: _get_seccion_romana(x, MAPA_CAPITULO_SECCION))\n",
    "    \n",
    "    panel_df['Txt_Seccion_Nombre'] = panel_df['Txt_Seccion_Romana'].map(SECCIONES_NOMBRES)\n",
    "    panel_df['Txt_Capitulo']       = code_full.str[:2].map(CAPITULOS_NOMBRES)\n",
    "    panel_df['Txt_Partida']        = code_full.str[:4].map(dict_partidas)\n",
    "    panel_df['Txt_Desdoblamiento'] = code_full.str[:5].map(dict_desdoblamiento)\n",
    "    panel_df['Txt_Subpartida']     = code_full.str[:6].map(dict_subpartidas)\n",
    "\n",
    "    # 6. Homogenización de Formatos de Texto\n",
    "    print(\"Formateando textos (Mayúsculas y Puntos)...\")\n",
    "    \n",
    "    panel_df['Txt_Seccion_Nombre'] = panel_df['Txt_Seccion_Nombre'].fillna('').astype(str).str.lower().str.capitalize()\n",
    "    panel_df['Txt_Seccion_Nombre'] = panel_df['Txt_Seccion_Nombre'].str.rstrip('.') + '.'\n",
    "    panel_df['Txt_Capitulo'] = panel_df['Txt_Capitulo'].fillna('').astype(str).str.rstrip('.') + '.'\n",
    "\n",
    "    panel_df['Codigo_Completo'] = panel_df['CODIGO']\n",
    "\n",
    "    # 7. Concatenación usando función auxiliar externa\n",
    "    print(\"Generando concatenación limpia...\")\n",
    "    panel_df['Texto_Concatenado'] = panel_df.apply(_concatenar_descripciones, axis=1)\n",
    "\n",
    "    # --- DEFINICIÓN DE ESTRUCTURAS DE SALIDA ---\n",
    "    cols_reducido = ['Codigo_Completo', 'Txt_Seccion_Romana', 'Show_Capitulo', 'Show_Partida', 'Show_Desdoblamiento', 'Show_Subpartida', 'Show_Fraccion', 'UNIDAD', 'IMP_IMP', 'IMP_EXP']\n",
    "    df_reducido = panel_df[cols_reducido].copy()\n",
    "    df_reducido.columns = ['Código Completo', 'Sección', 'Capítulo', 'Partida', 'Desdoblamiento', 'Subpartida', 'Fracción', 'Unidad', 'Imp. Imp.', 'Imp. Exp.']\n",
    "\n",
    "    cols_textual = ['Codigo_Completo', 'Txt_Seccion_Nombre', 'Txt_Capitulo', 'Txt_Partida', 'Txt_Desdoblamiento', 'Txt_Subpartida', 'DESCRIPCION', 'UNIDAD', 'IMP_IMP', 'IMP_EXP']\n",
    "    df_textual = panel_df[cols_textual].copy()\n",
    "    df_textual.columns = ['Código Completo', 'Nombre Sección', 'Nombre Capítulo', 'Nombre Partida', 'Nombre Desdoblamiento', 'Nombre Subpartida', 'Descripción Fracción', 'Unidad', 'Imp. Imp.', 'Imp. Exp.']\n",
    "\n",
    "    cols_extendido = ['Codigo_Completo', 'Txt_Seccion_Romana', 'Txt_Seccion_Nombre', 'Show_Capitulo', 'Txt_Capitulo', 'Show_Partida', 'Txt_Partida', 'Show_Desdoblamiento', 'Txt_Desdoblamiento', 'Show_Subpartida', 'Txt_Subpartida', 'Show_Fraccion', 'DESCRIPCION', 'UNIDAD', 'IMP_IMP', 'IMP_EXP']\n",
    "    df_extendido = panel_df[cols_extendido].copy()\n",
    "    df_extendido.columns = ['Código Completo', 'Sección', 'Nombre Sección', 'Capítulo', 'Nombre Capítulo', 'Partida', 'Nombre Partida', 'Desdob.', 'Nombre Desdoblamiento', 'Subpartida', 'Nombre Subpartida', 'Fracción', 'Descripción Fracción', 'Unidad', 'Imp. Imp.', 'Imp. Exp.']\n",
    "\n",
    "    cols_concat = ['Codigo_Completo', 'Texto_Concatenado', 'UNIDAD', 'IMP_IMP', 'IMP_EXP']\n",
    "    df_concatenado = panel_df[cols_concat].copy()\n",
    "    df_concatenado.columns = ['Código Completo', 'Descripción Completa Concatenada', 'Unidad', 'Imp. Imp.', 'Imp. Exp.']\n",
    "\n",
    "    # --- EXPORTACIÓN A EXCEL ---\n",
    "    nombre_salida = \"LIGIE_Limpia.xlsx\"\n",
    "    print(f\"Generando archivo Excel: {nombre_salida} ...\")\n",
    "\n",
    "    writer = pd.ExcelWriter(nombre_salida, engine='xlsxwriter')\n",
    "    workbook = writer.book\n",
    "\n",
    "    # Llamadas a función crítica de escritura\n",
    "    __escribir_hoja__(final_df, \"LIGIE\", writer, workbook) \n",
    "    __escribir_hoja__(df_reducido, \"Panel Reducido\", writer, workbook)\n",
    "    __escribir_hoja__(df_textual, \"Panel Textual\", writer, workbook)\n",
    "    __escribir_hoja__(df_extendido, \"Panel Extendido\", writer, workbook)\n",
    "    __escribir_hoja__(df_concatenado, \"Concatenado\", writer, workbook)\n",
    "\n",
    "    writer.close()\n",
    "    print(\"¡PROCESO FINALIZADO CON ÉXITO!\")\n",
    "\n",
    "else:\n",
    "    print(\"No se encontraron datos para exportar. Verifica el archivo PDF.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
